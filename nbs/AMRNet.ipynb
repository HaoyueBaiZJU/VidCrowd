{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import visualize, plot_data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/home/hheat/USERDIR/counting-bench/data'\n",
    "train_images = path + '/images'\n",
    "test_images = path + '/test_images/images'\n",
    "anno = path + '/annotation'\n",
    "density_maps = path + '/dmap_amr'\n",
    "\n",
    "LOG_PARA = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            #A.Resize(360,640,interpolation=2),\n",
    "            #A.RandomSizedCrop(min_max_height=(409, 512), height=409, width=512, p=1.0),\n",
    "            #A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=1.0),\n",
    "        ],\n",
    "        #additional_targets={'image': 'image','image1': 'image'}\n",
    "        #keypoint_params = A.KeypointParams(format='xy')\n",
    ")\n",
    "\n",
    "def get_train_image_only_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            #A.Resize(360,640),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "            ],p=0.9),\n",
    "            A.Blur(blur_limit=3,p=0.2),\n",
    "            A.Normalize(mean=mean,std=std,p=1.0,max_pixel_value=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        additional_targets={'image': 'image'}\n",
    "    )\n",
    "\n",
    "def get_valid_trainsforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            #A.Resize(360,640,interpolation=2),\n",
    "            A.Normalize(mean=mean,std=std,p=1.0,max_pixel_value=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# def get_valid_image_only_transforms():\n",
    "#     return A.Compose(\n",
    "#         [\n",
    "#             A.Resize(360,640),\n",
    "#         ],\n",
    "#         additional_targets={'image': 'image'}\n",
    "#     )\n",
    "\n",
    "mean = torch.tensor([0.4939, 0.4794, 0.4583])\n",
    "std = torch.tensor([0.2177, 0.2134, 0.2144])\n",
    "\n",
    "def denormalize(img):\n",
    "    img = img * std[...,None,None] + mean[...,None,None]\n",
    "    img = img.permute(1,2,0).cpu().numpy()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counting_Dataset(Dataset):\n",
    "    def __init__(self,path,image_fnames,dmap_folder,gt_folder=None,transforms=None,mosaic=False,downsample=4):\n",
    "        '''\n",
    "            path: root path \n",
    "            image_fnames: path of images\n",
    "            dmap_folder: density map folder, eg: /dmap\n",
    "            gt_folder: gt folder, currently set to visdrone xml format, modify _get_gt_data() if needed\n",
    "            transforms: iteratable, can be tuple / list ... etc\n",
    "            mosaic: mix up image and density map to form a new image, set to false by default\n",
    "            downsample: resize dmap\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.image_fnames = image_fnames\n",
    "        self.dmap_folder = path + dmap_folder\n",
    "        self.transforms = transforms\n",
    "        self.mosaic = mosaic\n",
    "        self.downsample = downsample\n",
    "        self.gt_folder = gt_folder # test purpose\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_fnames[idx]\n",
    "        \n",
    "        if self.mosaic and random.randint(0,1) < 0.5:\n",
    "            image, density_map, gt_points = self._load_mosaic_image_and_density_map(idx)\n",
    "        else:\n",
    "            image, density_map, gt_points = self._load_image_and_density_map(idx)\n",
    "        \n",
    "        h,w = image.shape[0]//self.downsample, image.shape[1]//self.downsample\n",
    "        image = cv2.resize(image,(w, h))\n",
    "        density_map = cv2.resize(density_map,(w//(self.downsample*2),h//(self.downsample*2)))#,interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Warning: doesn't work for cutout, uncommet transform and make fix code to enable cutout\n",
    "        # Reason: cutout doesn't apply to mask, so mask must be image. check 01a bottom for code\n",
    "        if self.transforms:\n",
    "            for tfms in self.transforms:\n",
    "                aug = tfms(**{\n",
    "                    'image': image,\n",
    "                    'mask': density_map,\n",
    "                    #'keypoints': gt_points\n",
    "                })\n",
    "                #image, density_map, gt_points = aug['image'], aug['mask'], aug['keypoints']\n",
    "                image, density_map = aug['image'], aug['mask'] # issue with previous keypoints (albumentation?)\n",
    "        \n",
    "        \n",
    "        return image, density_map, image_id, gt_points\n",
    "        \n",
    "    \n",
    "    def _get_dmap_name(self,fn):\n",
    "        mask_name = fn.split('/')[-1].split('.')[0]\n",
    "        mask_path = self.dmap_folder + '/' + mask_name + '.npy'\n",
    "        return mask_path\n",
    "    \n",
    "    def _load_image_and_density_map(self,idx):\n",
    "        image_fname = self.image_fnames[idx]\n",
    "        dmap_fname = self._get_dmap_name(image_fname)\n",
    "        image = cv2.imread(image_fname)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = image/255.\n",
    "        d_map = np.load(dmap_fname,allow_pickle=True)\n",
    "        \n",
    "        #sanity check gt\n",
    "        _, points = self._get_gt_data(idx)\n",
    "        # end sanity check\n",
    "        \n",
    "        return image, d_map, points\n",
    "    \n",
    "    def _load_mosaic_image_and_density_map(self,idx):\n",
    "        image_1, dmap_1, points_1 = self._load_image_and_density_map(idx)\n",
    "        while True:\n",
    "            idx_2 = random.randint(0,len(self.image_fnames)-1)\n",
    "            if idx != idx_2:\n",
    "                break\n",
    "        image_2, dmap_2, points_2 = self._load_image_and_density_map(idx_2)\n",
    "        \n",
    "        imsize = min(*image_1.shape[:2])\n",
    "        xc,yc = [int(random.uniform(imsize*0.4,imsize*0.6)) for _ in range(2)]\n",
    "        h,w = image_1.shape[0], image_1.shape[1]\n",
    "\n",
    "        pos = random.randint(0,1)\n",
    "        if pos == 0: #top left\n",
    "            x1a,y1a,x2a,y2a = 0,0,xc,yc # img_1\n",
    "            x1b,y1b,x2b,y2b = w-xc,h-yc,w,h # img_2\n",
    "        elif pos == 1: # top right\n",
    "            x1a,y1a,x2a,y2a = w-xc,0,w,yc\n",
    "            x1b,y1b,x2b,y2b = 0,h-yc,xc,h\n",
    "        elif pos == 2: # bottom left\n",
    "            x1a,y1a,x2a,y2a = 0,h-yc,xc,h\n",
    "            x1b,y1b,x2b,y2b = w-xc,0,w,yc\n",
    "        elif pos == 3: # bottom right\n",
    "            x1a,y1a,x2a,y2a = w-xc,h-yc,w,h\n",
    "            x1b,y1b,x2b,y2b = 0,0,xc,yc\n",
    "        \n",
    "        new_image = image_1.copy()\n",
    "        new_dmap = dmap_1.copy()\n",
    "        new_image[y1a:y2a,x1a:x2a] = image_2[y1b:y2b,x1b:x2b]\n",
    "        new_dmap[y1a:y2a,x1a:x2a] = dmap_2[y1b:y2b,x1b:x2b]\n",
    "        \n",
    "        #TODO: sanity check to see generate gt\n",
    "        \n",
    "        new_gt_points = self._get_mixed_gt_points(points_1,points_2,(x1a,y1a,x2a,y2a),(x1b,y1b,x2b,y2b),(h,w))\n",
    "        \n",
    "        return new_image, new_dmap, new_gt_points\n",
    "    \n",
    "    '''\n",
    "    The follow section blocks are for sanity check \n",
    "    to compare dmap.sum() with gt points\n",
    "    remove if needed\n",
    "    '''\n",
    "    def _get_mixed_gt_points(self,points_1,points_2,img_1_loc, img_2_loc,img_shape):\n",
    "#         fn_1, points_1 = self._get_gt_data(idx_1)\n",
    "#         fn_2, points_2 = self._get_gt_data(idx_2)\n",
    "        x1a,y1a,x2a,y2a = img_1_loc\n",
    "        x1b,y1b,x2b,y2b = img_2_loc\n",
    "        h,w = img_shape\n",
    "        \n",
    "        result_boxes = []\n",
    "        result_boxes.append(points_2)\n",
    "        result_boxes = np.concatenate(result_boxes,0)\n",
    "        padw = x1a-x1b\n",
    "        pady = y1a-y1b\n",
    "\n",
    "        result_boxes[:,0] += padw\n",
    "        result_boxes[:,1] += pady\n",
    "\n",
    "        np.clip(result_boxes[:,0],0,w,out=result_boxes[:,0])\n",
    "        np.clip(result_boxes[:,1],0,h,out=result_boxes[:,1])\n",
    "        result_boxes = result_boxes.astype(np.int32)\n",
    "\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,0] * result_boxes[:,1] > 0)]\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,0] < w)]\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,1] < h)]\n",
    "        \n",
    "        boxes = []\n",
    "        for (x,y) in points_1:\n",
    "            if x >= x1a and x <= x2a and y >= y1a and y <= y2a:\n",
    "                continue\n",
    "            else:\n",
    "                boxes.append((x,y))\n",
    "        if len(boxes) == 0:\n",
    "            return result_boxes\n",
    "        return np.concatenate((boxes, result_boxes),axis=0)\n",
    "    \n",
    "    def _get_gt_data(self,idx):\n",
    "        if not self.gt_folder:\n",
    "            return (None,0)\n",
    "        fn = self.image_fnames[idx]\n",
    "        anno_path = self.path + self.gt_folder + '/' + fn.split('/')[-1].split('.')[0] + '.mat'\n",
    "        test_data = loadmat(anno_path)\n",
    "        points = test_data['annotation'].astype(int)\n",
    "        return fn, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD LOG_PARA to density map\n",
    "\n",
    "class Crop_Dataset(Counting_Dataset):\n",
    "    def __init__(self,path,image_fnames,dmap_folder,gt_folder=None,transforms=None,mosaic=False,downsample=4,crop_size=512,method='train'):\n",
    "        super().__init__(path,image_fnames,dmap_folder,gt_folder,transforms,mosaic,downsample)\n",
    "        self.crop_size = crop_size\n",
    "        if method not in ['train','valid']:\n",
    "            raise Exception('Not Implement')\n",
    "        self.method = method\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        fn = self.image_fnames[idx]\n",
    "        \n",
    "        image,density_map,gt_points = self._load_image_and_density_map(idx)\n",
    "        h,w = image.shape[0], image.shape[1]\n",
    "        #image = cv2.resize(image,(w, h))\n",
    "        \n",
    "        \n",
    "        if self.method == 'train':\n",
    "            #h,w = image.shape[:2]\n",
    "            i,j = self._random_crop(h,w,self.crop_size,self.crop_size)\n",
    "            image = image[i:i+self.crop_size,j:j+self.crop_size]\n",
    "            density_map = density_map[i:i+self.crop_size,j:j+self.crop_size]\n",
    "            \n",
    "            gt_points = gt_points - [j,i]\n",
    "            mask = (gt_points[:,0] >=0 ) * (gt_points[:,0] <= self.crop_size) * (gt_points[:,1]>=0) * (gt_points[:,1]<=self.crop_size)\n",
    "            gt_points = gt_points[mask]\n",
    "            density_map = cv2.resize(density_map,(self.crop_size//self.downsample,self.crop_size//self.downsample))\n",
    "            \n",
    "        else:\n",
    "            density_map = cv2.resize(density_map,(w//self.downsample,h//self.downsample))#,interpolation=cv2.INTER_NEAREST)\n",
    "            #density_map = density_map[1:-1,:]\n",
    "        \n",
    "        if self.transforms:\n",
    "            for tfms in self.transforms:\n",
    "                aug = tfms(**{\n",
    "                    'image': image,\n",
    "                    'mask': density_map,\n",
    "                    #'keypoints': gt_points\n",
    "                })\n",
    "                #image, density_map, gt_points = aug['image'], aug['mask'], aug['keypoints']\n",
    "                image, density_map = aug['image'], aug['mask'] # issue with previous keypoints (albumentation?)\n",
    "        return image, density_map*LOG_PARA, fn, gt_points\n",
    "    \n",
    "    def _random_crop(self, im_h, im_w, crop_h, crop_w):\n",
    "        res_h = im_h - crop_h\n",
    "        res_w = im_w - crop_w\n",
    "        i = random.randint(0, res_h)\n",
    "        j = random.randint(0, res_w)\n",
    "        return i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp = glob(train_images + '/*.jpg')\n",
    "test_fp = glob(test_images + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/home/hheat/USERDIR/counting-bench/data/images/11_233.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/12_240.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/08_113.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/03_319.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/06_176.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/05_105.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/11_204.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/14_253.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/14_129.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/20_248.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(len(train_fp) * 0.8)\n",
    "train_fp[0:split][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Crop_Dataset(path=path,\n",
    "                             image_fnames=train_fp[:split],dmap_folder='/dmap_amr',\n",
    "                             gt_folder='/annotation',\n",
    "                             transforms=[get_train_transforms(),get_train_image_only_transforms()],\n",
    "                             downsample=1,\n",
    "                             crop_size=784\n",
    "                                )\n",
    "\n",
    "valid_dataset = Crop_Dataset(path=path,\n",
    "                             image_fnames=test_fp,dmap_folder='/dmap_amr',\n",
    "                             gt_folder='/annotation',\n",
    "                             transforms=[get_valid_trainsforms()],\n",
    "                             method='valid',\n",
    "                             downsample=1,\n",
    "                             crop_size=784\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 16\n",
    "    batch_size = 16\n",
    "    n_epochs = 120\n",
    "    lr = 0.0002\n",
    "\n",
    "    folder = 'AMRNet-7.19-784'\n",
    "    downsample = 1\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = True  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = False  # do scheduler.step after validation stage loss\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "    scheduler_params = dict(\n",
    "        max_lr=1e-4,\n",
    "        #total_steps = len(train_dataset) // 4 * n_epochs, # gradient accumulation\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "        pct_start=0.2,\n",
    "        anneal_strategy='cos', \n",
    "        final_div_factor=10**5\n",
    "    )\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "#     scheduler_params = dict(\n",
    "#         mode='min',\n",
    "#         factor=0.5,\n",
    "#         patience=1,\n",
    "#         verbose=False, \n",
    "#         threshold=0.0001,\n",
    "#         threshold_mode='abs',\n",
    "#         cooldown=0, \n",
    "#         min_lr=1e-8,\n",
    "#         eps=1e-08\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class VGG16_LCM(nn.Module):\n",
    "    def __init__(self, load_weights=True):\n",
    "        super(VGG16_LCM, self).__init__()\n",
    "\n",
    "        self.layer5 = self.VGG_make_layers([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M',\n",
    "                                            512, 512, 512, 'M', 512, 512, 512, 'M'])\n",
    "\n",
    "        self.reg_layer = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, 1),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        if load_weights:\n",
    "            mod = models.vgg16(pretrained=False)\n",
    "            pretrain_path = './vgg16-397923af.pth'\n",
    "            mod.load_state_dict(torch.load(pretrain_path))\n",
    "            print(\"loaded pretrain model: \" + pretrain_path)\n",
    "\n",
    "            self._initialize_weights()\n",
    "            self.layer5.load_state_dict(mod.features[0:31].state_dict())\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.layer5(x)\n",
    "        x = self.reg_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def VGG_make_layers(self, cfg, in_channels=3, batch_norm=False, dilation=1):\n",
    "        d_rate = dilation\n",
    "        layers = []\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate, dilation=d_rate)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_make_layers(cfg, in_channels=3, batch_norm=False, dilation=1):\n",
    "        d_rate = dilation\n",
    "        layers = []\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate, dilation=d_rate)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "vgg = VGG_make_layers([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M',\n",
    "                                            512, 512, 512, 'M', 512, 512, 512, 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class VGG16_LCM_REG(nn.Module):\n",
    "    def __init__(self, load_weights=False, stage_num=[3,3,3], count_range=100, lambda_i=1., lambda_k=1.):\n",
    "        super(VGG16_LCM_REG, self).__init__()\n",
    "\n",
    "        # cfg\n",
    "        self.stage_num = stage_num\n",
    "        self.lambda_i = lambda_i\n",
    "        self.lambda_k = lambda_k\n",
    "        self.count_range = count_range\n",
    "        self.multi_fuse = True\n",
    "        self.soft_interval = True\n",
    "\n",
    "        self.layer3 = self.VGG_make_layers([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512])\n",
    "        self.layer4 = self.VGG_make_layers(['M', 512, 512, 512], in_channels=512)\n",
    "        self.layer5 = self.VGG_make_layers(['M', 512, 512, 512], in_channels=512)\n",
    "\n",
    "        if self.multi_fuse:\n",
    "            self.fuse_layer5 = DC_layer(level=0)\n",
    "            self.fuse_layer4 = DC_layer(level=1)\n",
    "            self.fuse_layer3 = DC_layer(level=2)\n",
    "\n",
    "        self.count_layer5 = Count_layer(pool=2)\n",
    "        self.count_layer4 = Count_layer(pool=4)\n",
    "        self.count_layer3 = Count_layer(pool=8)\n",
    "        \n",
    "        if self.soft_interval:\n",
    "            self.layer5_k = nn.Sequential(\n",
    "                nn.Conv2d(512, 1, kernel_size=1),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "            self.layer4_k = nn.Sequential(\n",
    "                nn.Conv2d(512, 1, kernel_size=1),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "            self.layer3_k = nn.Sequential(\n",
    "                nn.Conv2d(512, 1, kernel_size=1),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "        \n",
    "            self.layer5_i = nn.Sequential(\n",
    "                nn.Conv2d(512, self.stage_num[0], kernel_size=1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "            self.layer4_i = nn.Sequential(\n",
    "                nn.Conv2d(512, self.stage_num[1], kernel_size=1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "            self.layer3_i = nn.Sequential(\n",
    "                nn.Conv2d(512, self.stage_num[2], kernel_size=1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "        self.layer5_p = nn.Sequential(\n",
    "            nn.Conv2d(512, self.stage_num[0], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer4_p = nn.Sequential(\n",
    "            nn.Conv2d(512, self.stage_num[1], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer3_p = nn.Sequential(\n",
    "            nn.Conv2d(512, self.stage_num[2], kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        if load_weights:\n",
    "            #self._initialize_weights()\n",
    "            \n",
    "            mod = models.vgg16(pretrained=False)\n",
    "            pretrain_path = './vgg16-397923af.pth'\n",
    "            mod.load_state_dict(torch.load(pretrain_path))\n",
    "\n",
    "            new_state_dict = OrderedDict()\n",
    "            for key, params in mod.features[0:23].state_dict().items():\n",
    "                new_state_dict[key] = params\n",
    "            self.layer3.load_state_dict(new_state_dict)\n",
    "\n",
    "            new_state_dict = OrderedDict()\n",
    "            for key, params in mod.features[23:30].state_dict().items():\n",
    "                key = str(int(key[:2]) - 23) + key[2:]\n",
    "                new_state_dict[key] = params\n",
    "            self.layer4.load_state_dict(new_state_dict)\n",
    "\n",
    "            new_state_dict = OrderedDict()\n",
    "            for key, params in mod.features[23:30].state_dict().items():\n",
    "                key = str(int(key[:2]) - 23) + key[2:]\n",
    "                new_state_dict[key] = params\n",
    "            self.layer5.load_state_dict(new_state_dict)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x3 = self.layer3(x)\n",
    "        x4 = self.layer4(x3)\n",
    "        x5 = self.layer5(x4)\n",
    "\n",
    "        if self.multi_fuse:\n",
    "            x5 = self.fuse_layer5(x5)\n",
    "            x4 = self.fuse_layer4(x4)\n",
    "            x3 = self.fuse_layer3(x3)\n",
    "\n",
    "        x5_= self.count_layer5(x5)\n",
    "        p5 = self.layer5_p(x5_)\n",
    "        if self.soft_interval:\n",
    "            k5 = self.layer5_k(x5_)\n",
    "            i5 = self.layer5_i(x5_)\n",
    "\n",
    "        x4_ = self.count_layer4(x4)\n",
    "        p4 = self.layer4_p(x4_)\n",
    "        if self.soft_interval:\n",
    "            k4 = self.layer4_k(x4_)\n",
    "            i4 = self.layer4_i(x4_)\n",
    "\n",
    "        x3_ = self.count_layer3(x3)\n",
    "        p3 = self.layer3_p(x3_)\n",
    "        if self.soft_interval:\n",
    "            k3 = self.layer3_k(x3_)\n",
    "            i3 = self.layer3_i(x3_)\n",
    "\n",
    "        stage1_regress = p5[:, 0, :, :] * 0\n",
    "        stage2_regress = p4[:, 0, :, :] * 0\n",
    "        stage3_regress = p3[:, 0, :, :] * 0\n",
    "\n",
    "        for index in range(self.stage_num[0]):\n",
    "            if self.soft_interval:\n",
    "                stage1_regress = stage1_regress + (float(index) + self.lambda_i * i5[:, index, :, :]) * p5[:, index, :, :]\n",
    "            else:\n",
    "                stage1_regress = stage1_regress + float(index) * p5[:, index, :, :]\n",
    "        stage1_regress = torch.unsqueeze(stage1_regress, 1)\n",
    "        if self.soft_interval:\n",
    "            stage1_regress = stage1_regress / ( float(self.stage_num[0]) * (1. + self.lambda_k * k5) )\n",
    "        else:\n",
    "            stage1_regress = stage1_regress / float(self.stage_num[0])\n",
    "\n",
    "\n",
    "        for index in range(self.stage_num[1]):\n",
    "            if self.soft_interval:\n",
    "                stage2_regress = stage2_regress + (float(index) + self.lambda_i * i4[:, index, :, :]) * p4[:, index, :, :]\n",
    "            else:\n",
    "                stage2_regress = stage2_regress + float(index) * p4[:, index, :, :]\n",
    "        stage2_regress = torch.unsqueeze(stage2_regress, 1)\n",
    "        if self.soft_interval:\n",
    "            stage2_regress = stage2_regress / ( (float(self.stage_num[0]) * (1. + self.lambda_k * k5)) *\n",
    "                                                (float(self.stage_num[1]) * (1. + self.lambda_k * k4)) )\n",
    "        else:\n",
    "            stage2_regress = stage2_regress / float( self.stage_num[0] * self.stage_num[1] )\n",
    "\n",
    "\n",
    "        for index in range(self.stage_num[2]):\n",
    "            if self.soft_interval:\n",
    "                stage3_regress = stage3_regress + (float(index) + self.lambda_i * i3[:, index, :, :]) * p3[:, index, :, :]\n",
    "            else:\n",
    "                stage3_regress = stage3_regress + float(index) * p3[:, index, :, :]\n",
    "        stage3_regress = torch.unsqueeze(stage3_regress, 1)\n",
    "        if self.soft_interval:\n",
    "            stage3_regress = stage3_regress / ( (float(self.stage_num[0]) * (1. + self.lambda_k * k5)) *\n",
    "                                                (float(self.stage_num[1]) * (1. + self.lambda_k * k4)) *\n",
    "                                                (float(self.stage_num[2]) * (1. + self.lambda_k * k3)) )\n",
    "        else:\n",
    "            stage3_regress = stage3_regress / float( self.stage_num[0] * self.stage_num[1] * self.stage_num[2] )\n",
    "\n",
    "        # regress_count = stage1_regress * self.count_range\n",
    "        # regress_count = (stage1_regress + stage2_regress) * self.count_range\n",
    "        regress_count = (stage1_regress + stage2_regress + stage3_regress) * self.count_range\n",
    "\n",
    "        return regress_count\n",
    "\n",
    "    def VGG_make_layers(self, cfg, in_channels=3, batch_norm=False, dilation=1):\n",
    "        d_rate = dilation\n",
    "        layers = []\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate, dilation=d_rate)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Count_layer(nn.Module):\n",
    "    def __init__(self, inplanes=512, pool=2):\n",
    "        super(Count_layer, self).__init__()\n",
    "        self.avgpool_layer = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, inplanes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d((pool, pool), stride=pool),\n",
    "        )\n",
    "        self.maxpool_layer = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, inplanes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((pool, pool), stride=pool),\n",
    "        )\n",
    "        self.conv1x1= nn.Sequential(\n",
    "            nn.Conv2d(inplanes*2, inplanes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_avg = self.avgpool_layer(x)\n",
    "        x_max = self.maxpool_layer(x)\n",
    "\n",
    "        x = torch.cat([x_avg, x_max], dim=1)\n",
    "        x = self.conv1x1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DC_layer(nn.Module):\n",
    "    def __init__(self, level, fuse=False):\n",
    "        super(DC_layer, self).__init__()\n",
    "        self.level = level\n",
    "        self.conv1x1_d1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.conv1x1_d2 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.conv1x1_d3 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.conv1x1_d4 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "\n",
    "        self.conv_d1 = nn.Conv2d(512, 512, kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv_d2 = nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2)\n",
    "        self.conv_d3 = nn.Conv2d(512, 512, kernel_size=3, padding=3, dilation=3)\n",
    "        self.conv_d4 = nn.Conv2d(512, 512, kernel_size=3, padding=4, dilation=4)\n",
    "        \n",
    "        self.fuse = fuse\n",
    "        if self.fuse:\n",
    "            self.fuse = nn.Conv2d(512*2, 512, kernel_size=3, padding=1)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1x1_d1(x)\n",
    "        x2 = self.conv1x1_d2(x)\n",
    "        x3 = self.conv1x1_d3(x)\n",
    "        x4 = self.conv1x1_d4(x)\n",
    "\n",
    "        x1 = self.conv_d1(x1)\n",
    "        x2 = self.conv_d2(x2)\n",
    "        x3 = self.conv_d3(x3)\n",
    "        x4 = self.conv_d4(x4)\n",
    "\n",
    "        # x = torch.cat([x1, x2, x3, x4], dim=1)\n",
    "        # x = self.relu(self.fuse(x))\n",
    "        x = Maxout(x1, x2, x3, x4)\n",
    "        return x\n",
    "\n",
    "def Maxout(x1, x2, x3, x4):\n",
    "    mask_1 = torch.ge(x1, x2)\n",
    "    mask_1 = mask_1.float()\n",
    "    x = mask_1 * x1 + (1-mask_1) * x2\n",
    "\n",
    "    mask_2 = torch.ge(x, x3)\n",
    "    mask_2 = mask_2.float()\n",
    "    x = mask_2 * x + (1-mask_2) * x3\n",
    "\n",
    "    mask_3 = torch.ge(x, x4)\n",
    "    mask_3 = mask_3.float()\n",
    "    x = mask_3 * x + (1-mask_3) * x4\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img, dmap, fn, points = train_dataset[250]\n",
    "#kernel6=64\n",
    "#filter6 = torch.ones(1, 1, kernel6, kernel6, requires_grad=False)\n",
    "#gt_map_6 = F.conv2d(dmap.unsqueeze(0).unsqueeze(0), filter6, stride=kernel6)\n",
    "#gt_map_6.shape\n",
    "#mm = VGG16_LCM_REG(True)\n",
    "#count_map = vgg(img.unsqueeze(0))\n",
    "#print(count_map.shape)\n",
    "#loss = nn.MSELoss()\n",
    "#loss(count_map, gt_map_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss_MCNN(preds,targs):\n",
    "    return nn.MSELoss()(preds,targs)\n",
    "\n",
    "def MAELoss_MCNN(preds,targs,upsample):\n",
    "    return nn.L1Loss()((preds/LOG_PARA).sum(dim=[-1,-2])*upsample*upsample, (targs/LOG_PARA).sum(dim=[-1,-2])*upsample*upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#opt_level ='O1' # apex\n",
    "\n",
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10**5\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        \n",
    "        #self.model, self.optimizer = amp.initialize(self.model,self.optimizer,opt_level=opt_level) # apex\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.criterion = MSELoss_MCNN\n",
    "        self.metric = MAELoss_MCNN\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "        \n",
    "        # self.iters_to_accumulate = 4 # gradient accumulation\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, mae_loss = self.train_one_epoch(train_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, mae_loss: {mae_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, mae_loss = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, mae_loss: {mae_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        mae_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, density_maps, fns, gt_pts) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'mse_loss: {summary_loss.avg:.8f}, ' + \\\n",
    "                        f'mae_loss: {mae_loss.avg:.8f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.cuda().float()\n",
    "                density_maps = density_maps.cuda().float()\n",
    "                \n",
    "\n",
    "                #preds = self.model(images)\n",
    "                with torch.cuda.amp.autocast(): #native fp16\n",
    "                    preds = self.model(images)\n",
    "                    kernel6 = 64\n",
    "                    filter6 = torch.ones(1, 1, kernel6, kernel6, requires_grad=False)\n",
    "                    density_maps = F.conv2d(density_maps, filter6.cuda(), stride=kernel6)\n",
    "                    loss = self.criterion(preds,density_maps/LOG_PARA)\n",
    "                    metric_loss = self.metric(preds,density_maps,self.config.downsample)\n",
    "                mae_loss.update(metric_loss.detach().item(),batch_size)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "                \n",
    "            #if step == 20:\n",
    "            #    break\n",
    "\n",
    "        return summary_loss, mae_loss\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        mae_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, density_maps, fns, gt_pts) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'mse_loss: {summary_loss.avg:.8f}, ' + \\\n",
    "                        f'mae_loss: {mae_loss.avg:.8f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            \n",
    "            images = images.cuda().float()\n",
    "            batch_size = images.shape[0]\n",
    "            density_maps = density_maps.cuda().float()\n",
    "            \n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast(): #native fp16\n",
    "                preds = self.model(images)\n",
    "                kernel6 = 64\n",
    "                filter6 = torch.ones(1, 1, kernel6, kernel6, requires_grad=False)\n",
    "                density_maps = F.conv2d(density_maps, filter6.cuda(), stride=kernel6).cuda()\n",
    "                loss = self.criterion(preds,density_maps/LOG_PARA)\n",
    "                metric_loss = self.metric(preds.detach(),density_maps.detach(),self.config.downsample)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            # loss = loss / self.iters_to_accumulate # gradient accumulation\n",
    "            \n",
    "#             with amp.scale_loss(loss,self.optimizer) as scaled_loss: # apex\n",
    "#                 scaled_loss.backward()\n",
    "            #loss.backward()\n",
    "\n",
    "            \n",
    "            mae_loss.update(metric_loss.detach().item(),batch_size)\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "            \n",
    "            #self.optimizer.step()\n",
    "            self.scaler.step(self.optimizer) # native fp16\n",
    "            \n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            self.scaler.update() #native fp16\n",
    "                \n",
    "                \n",
    "#             if (step+1) % self.iters_to_accumulate == 0: # gradient accumulation\n",
    "\n",
    "#                 self.optimizer.step()\n",
    "#                 self.optimizer.zero_grad()\n",
    "\n",
    "#                 if self.config.step_scheduler:\n",
    "#                     self.scheduler.step()\n",
    "                    \n",
    "            #if step == 20:\n",
    "            #    break\n",
    "\n",
    "        return summary_loss, mae_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_summary_loss': self.best_summary_loss,\n",
    "            'epoch': self.epoch,\n",
    "            #'amp': amp.state_dict() # apex\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
    "        self.epoch = checkpoint['epoch'] + 1\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_init(host_addr, rank, local_rank, world_size, port=23456):\n",
    "    host_addr_full = 'tcp://' + host_addr + ':' + str(port)\n",
    "    torch.distributed.init_process_group(\"gloo\", init_method=host_addr_full,\n",
    "                                         rank=rank, world_size=world_size)\n",
    "    assert torch.distributed.is_initialized()\n",
    "    \n",
    "def get_ip(iplist):\n",
    "        ip = iplist.split('[')[0] + iplist.split('[')[1].split('-')[0]\n",
    "        return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu05 0 0 1\n"
     ]
    }
   ],
   "source": [
    "rank = int(os.environ['SLURM_PROCID'])\n",
    "local_rank = int(os.environ['SLURM_LOCALID'])\n",
    "world_size = int(os.environ['SLURM_NTASKS'])\n",
    "iplist = os.environ['SLURM_JOB_NODELIST']\n",
    "#ip = get_ip(iplist)\n",
    "print(iplist, rank, local_rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_init(iplist, rank, local_rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "val_sampler = DistributedSampler(valid_dataset, num_replicas=world_size, rank=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs, dmaps, fns, gt_points = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    dmaps = torch.stack(dmaps).unsqueeze(1)\n",
    "    return imgs,dmaps,fns,gt_points\n",
    "\n",
    "def run_training():\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        #sampler=RandomSampler(train_dataset),\n",
    "        sampler=train_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size//4,\n",
    "        num_workers=TrainGlobalConfig.num_workers//2,\n",
    "        shuffle=False,\n",
    "        #sampler=SequentialSampler(valid_dataset),\n",
    "        sampler=val_sampler,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "#     fitter.load(f'{fitter.base_dir}/last-checkpoint.bin')\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16_LCM_REG().cuda()\n",
    "net = DistributedDataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2021-07-15T02:45:18.108357\n",
      "LR: 3.9999999999999996e-05\n",
      "[RESULT]: Train. Epoch: 0, mse_loss: 35.22208995, time: 67.39928 time: 41.24997\n",
      "[RESULT]: Train. Epoch: 0, mae_loss: 10.52420766, time: 67.40969\n",
      "[RESULT]: Val. Epoch: 0, mse_loss: 20.72305820, time: 26.64149, time: 24.28690\n",
      "[RESULT]: Val. Epoch: 0, mae_loss: 131.89949799, time: 26.65091\n",
      "\n",
      "2021-07-15T02:46:57.628189\n",
      "LR: 4.013088592123436e-05\n",
      "[RESULT]: Train. Epoch: 1, mse_loss: 26.28625470, time: 49.67701 time: 35.46557\n",
      "[RESULT]: Train. Epoch: 1, mae_loss: 12.17845912, time: 49.68969\n",
      "[RESULT]: Val. Epoch: 1, mse_loss: 20.15568488, time: 19.35900, time: 17.07036\n",
      "[RESULT]: Val. Epoch: 1, mae_loss: 131.18062955, time: 19.36896\n",
      "\n",
      "2021-07-15T02:48:11.707354\n",
      "LR: 4.0523472305252516e-05\n",
      "[RESULT]: Train. Epoch: 2, mse_loss: 18.89772458, time: 40.28414 time: 35.96966\n",
      "[RESULT]: Train. Epoch: 2, mae_loss: 11.46640210, time: 40.29348\n",
      "[RESULT]: Val. Epoch: 2, mse_loss: 20.53398686, time: 20.04821, time: 17.71468\n",
      "[RESULT]: Val. Epoch: 2, mae_loss: 132.05387261, time: 20.06229\n",
      "\n",
      "2021-07-15T02:49:14.615522\n",
      "LR: 4.11775450519273e-05\n",
      "[RESULT]: Train. Epoch: 3, mse_loss: 14.08491809, time: 40.45833time: 36.352724\n",
      "[RESULT]: Train. Epoch: 3, mae_loss: 9.82313104, time: 40.46920\n",
      "[RESULT]: Val. Epoch: 3, mse_loss: 16.38682293, time: 19.09119, time: 16.77996\n",
      "[RESULT]: Val. Epoch: 3, mae_loss: 132.10702369, time: 19.10366\n",
      "\n",
      "2021-07-15T02:50:18.962016\n",
      "LR: 4.2092747457450294e-05\n",
      "[RESULT]: Train. Epoch: 4, mse_loss: 12.19087494, time: 38.81153 time: 34.48462\n",
      "[RESULT]: Train. Epoch: 4, mae_loss: 10.73766538, time: 38.82194\n",
      "[RESULT]: Val. Epoch: 4, mse_loss: 15.11909024, time: 18.87514, time: 16.55342\n",
      "[RESULT]: Val. Epoch: 4, mae_loss: 131.93957738, time: 18.88587\n",
      "\n",
      "2021-07-15T02:51:22.142667\n",
      "LR: 4.326858040886339e-05\n",
      "[RESULT]: Train. Epoch: 5, mse_loss: 10.97966934, time: 39.90349 time: 35.67941\n",
      "[RESULT]: Train. Epoch: 5, mae_loss: 11.01437378, time: 39.91260\n",
      "[RESULT]: Val. Epoch: 5, mse_loss: 14.32251020, time: 19.18901, time: 16.71103\n",
      "[RESULT]: Val. Epoch: 5, mae_loss: 131.91619255, time: 19.19302\n",
      "\n",
      "2021-07-15T02:52:26.644902\n",
      "LR: 4.470440265625384e-05\n",
      "[RESULT]: Train. Epoch: 6, mse_loss: 10.66198469, time: 40.41580 time: 36.21342\n",
      "[RESULT]: Train. Epoch: 6, mae_loss: 10.85889896, time: 40.42627\n",
      "[RESULT]: Val. Epoch: 6, mse_loss: 13.77504964, time: 19.42052, time: 16.90733\n",
      "[RESULT]: Val. Epoch: 6, mae_loss: 131.68614088, time: 19.43173\n",
      "\n",
      "2021-07-15T02:53:32.147660\n",
      "LR: 4.6399431162465025e-05\n",
      "[RESULT]: Train. Epoch: 7, mse_loss: 9.84388127, time: 40.41987 time: 36.073761\n",
      "[RESULT]: Train. Epoch: 7, mae_loss: 10.31192741, time: 40.43320\n",
      "[RESULT]: Val. Epoch: 7, mse_loss: 14.40745220, time: 18.43215, time: 15.91354\n",
      "[RESULT]: Val. Epoch: 7, mae_loss: 131.89438375, time: 18.44389\n",
      "\n",
      "2021-07-15T02:54:33.562623\n",
      "LR: 4.835274153013199e-05\n",
      "[RESULT]: Train. Epoch: 8, mse_loss: 10.91931756, time: 40.82426 time: 36.12822\n",
      "[RESULT]: Train. Epoch: 8, mae_loss: 12.06307634, time: 40.83618\n",
      "[RESULT]: Val. Epoch: 8, mse_loss: 16.48954955, time: 19.74388, time: 17.28336\n",
      "[RESULT]: Val. Epoch: 8, mae_loss: 132.20721617, time: 19.75590\n",
      "\n",
      "2021-07-15T02:55:37.029709\n",
      "LR: 5.056326850580938e-05\n",
      "[RESULT]: Train. Epoch: 9, mse_loss: 9.70812920, time: 41.08116 time: 36.85508\n",
      "[RESULT]: Train. Epoch: 9, mae_loss: 11.00923643, time: 41.09223\n",
      "[RESULT]: Val. Epoch: 9, mse_loss: 14.30844684, time: 19.99788, time: 17.26295\n",
      "[RESULT]: Val. Epoch: 9, mae_loss: 131.96211134, time: 20.00843\n",
      "\n",
      "2021-07-15T02:56:40.635075\n",
      "LR: 5.30298065609154e-05\n",
      "[RESULT]: Train. Epoch: 10, mse_loss: 9.42991831, time: 40.46395time: 36.37258\n",
      "[RESULT]: Train. Epoch: 10, mae_loss: 10.05834979, time: 40.47702\n",
      "[RESULT]: Val. Epoch: 10, mse_loss: 13.60993251, time: 20.12688 time: 17.37819\n",
      "[RESULT]: Val. Epoch: 10, mae_loss: 131.77597664, time: 20.13721\n",
      "\n",
      "2021-07-15T02:57:46.675377\n",
      "LR: 5.57510105491767e-05\n",
      "[RESULT]: Train. Epoch: 11, mse_loss: 9.41561983, time: 39.74144time: 35.714131\n",
      "[RESULT]: Train. Epoch: 11, mae_loss: 11.12961501, time: 39.75341\n",
      "[RESULT]: Val. Epoch: 11, mse_loss: 12.77613787, time: 19.42395 time: 17.03366\n",
      "[RESULT]: Val. Epoch: 11, mae_loss: 131.83267067, time: 19.43517\n",
      "\n",
      "2021-07-15T02:58:51.523778\n",
      "LR: 5.872539644021467e-05\n",
      "[RESULT]: Train. Epoch: 12, mse_loss: 8.52854543, time: 39.88287time: 35.72679\n",
      "[RESULT]: Train. Epoch: 12, mae_loss: 10.20990905, time: 39.89266\n",
      "[RESULT]: Val. Epoch: 12, mse_loss: 11.88045797, time: 19.22881 time: 16.89736\n",
      "[RESULT]: Val. Epoch: 12, mae_loss: 131.66683379, time: 19.24118\n",
      "\n",
      "2021-07-15T02:59:55.990520\n",
      "LR: 6.195134212887306e-05\n",
      "[RESULT]: Train. Epoch: 13, mse_loss: 11.00549807, time: 39.14540time: 35.35330\n",
      "[RESULT]: Train. Epoch: 13, mae_loss: 11.33153788, time: 39.15521\n",
      "[RESULT]: Val. Epoch: 13, mse_loss: 13.35494979, time: 19.93965 time: 17.64185\n",
      "[RESULT]: Val. Epoch: 13, mae_loss: 131.80450112, time: 19.95022\n",
      "\n",
      "2021-07-15T03:00:57.776082\n",
      "LR: 6.542708831984673e-05\n",
      "[RESULT]: Train. Epoch: 14, mse_loss: 9.15543327, time: 39.86438ime: 35.82803\n",
      "[RESULT]: Train. Epoch: 14, mae_loss: 9.55624798, time: 39.87502\n",
      "[RESULT]: Val. Epoch: 14, mse_loss: 13.02381979, time: 19.24523 time: 16.78988\n",
      "[RESULT]: Val. Epoch: 14, mae_loss: 131.80673799, time: 19.25768\n",
      "\n",
      "2021-07-15T03:01:59.759707\n",
      "LR: 6.91507394871264e-05\n",
      "[RESULT]: Train. Epoch: 15, mse_loss: 10.25158165, time: 40.29143time: 36.07421\n",
      "[RESULT]: Train. Epoch: 15, mae_loss: 11.27408044, time: 40.30282\n",
      "[RESULT]: Val. Epoch: 15, mse_loss: 11.52588365, time: 18.75060 time: 16.38910\n",
      "[RESULT]: Val. Epoch: 15, mae_loss: 131.84084029, time: 18.76126\n",
      "\n",
      "2021-07-15T03:03:04.009177\n",
      "LR: 7.31202649077396e-05\n",
      "[RESULT]: Train. Epoch: 16, mse_loss: 9.19061034, time: 39.85775time: 35.496238\n",
      "[RESULT]: Train. Epoch: 16, mae_loss: 11.25763228, time: 39.86859\n",
      "[RESULT]: Val. Epoch: 16, mse_loss: 12.38658596, time: 18.85080 time: 16.15537\n",
      "[RESULT]: Val. Epoch: 16, mae_loss: 131.86545526, time: 18.86088\n",
      "\n",
      "2021-07-15T03:04:05.602387\n",
      "LR: 7.733349976922163e-05\n",
      "[RESULT]: Train. Epoch: 17, mse_loss: 9.02201642, time: 39.84612time: 35.94544\n",
      "[RESULT]: Train. Epoch: 17, mae_loss: 10.30685117, time: 39.85847\n",
      "[RESULT]: Val. Epoch: 17, mse_loss: 11.01945087, time: 20.10240 time: 17.75154\n",
      "[RESULT]: Val. Epoch: 17, mae_loss: 131.89380028, time: 20.11298\n",
      "\n",
      "2021-07-15T03:05:10.649448\n",
      "LR: 8.178814635021315e-05\n",
      "[RESULT]: Train. Epoch: 18, mse_loss: 9.20317551, time: 40.61305time: 36.30165\n",
      "[RESULT]: Train. Epoch: 18, mae_loss: 10.28802036, time: 40.62566\n",
      "[RESULT]: Val. Epoch: 18, mse_loss: 12.83903690, time: 19.36691 time: 17.17526\n",
      "[RESULT]: Val. Epoch: 18, mae_loss: 131.49761854, time: 19.37680\n",
      "\n",
      "2021-07-15T03:06:13.516511\n",
      "LR: 8.648177527354123e-05\n",
      "[RESULT]: Train. Epoch: 19, mse_loss: 9.16173599, time: 41.05363time: 36.908391\n",
      "[RESULT]: Train. Epoch: 19, mae_loss: 10.81546325, time: 41.06615\n",
      "[RESULT]: Val. Epoch: 19, mse_loss: 12.35191856, time: 19.63147 time: 17.11588\n",
      "[RESULT]: Val. Epoch: 19, mae_loss: 131.61277480, time: 19.64426\n",
      "\n",
      "2021-07-15T03:07:16.683614\n",
      "LR: 9.141182683109958e-05\n",
      "[RESULT]: Train. Epoch: 20, mse_loss: 7.23766549, time: 40.53864time: 36.47259\n",
      "[RESULT]: Train. Epoch: 20, mae_loss: 10.62216268, time: 40.54883\n",
      "[RESULT]: Val. Epoch: 20, mse_loss: 11.90802178, time: 18.72965 time: 16.27514\n",
      "[RESULT]: Val. Epoch: 20, mae_loss: 131.82372502, time: 18.74257\n",
      "\n",
      "2021-07-15T03:08:18.533813\n",
      "LR: 9.657561237980518e-05\n",
      "[RESULT]: Train. Epoch: 21, mse_loss: 7.83412468, time: 40.47416time: 36.35008\n",
      "[RESULT]: Train. Epoch: 21, mae_loss: 11.07205395, time: 40.48479\n",
      "[RESULT]: Val. Epoch: 21, mse_loss: 11.88702361, time: 19.34157 time: 17.03167\n",
      "[RESULT]: Val. Epoch: 21, mae_loss: 131.57504890, time: 19.35156\n",
      "\n",
      "2021-07-15T03:09:21.086529\n",
      "LR: 0.0001019703158078722\n",
      "[RESULT]: Train. Epoch: 22, mse_loss: 7.81471232, time: 39.54457time: 35.73182\n",
      "[RESULT]: Train. Epoch: 22, mae_loss: 10.94002826, time: 39.55435\n",
      "[RESULT]: Val. Epoch: 22, mse_loss: 10.10140535, time: 19.98206 time: 17.52462\n",
      "[RESULT]: Val. Epoch: 22, mae_loss: 131.66935694, time: 19.99149\n",
      "\n",
      "2021-07-15T03:10:26.029145\n",
      "LR: 0.00010759299507060089\n",
      "[RESULT]: Train. Epoch: 23, mse_loss: 9.63424580, time: 40.07793time: 35.869987\n",
      "[RESULT]: Train. Epoch: 23, mae_loss: 11.44316514, time: 40.08967\n",
      "[RESULT]: Val. Epoch: 23, mse_loss: 12.41686019, time: 19.88510 time: 17.67737\n",
      "[RESULT]: Val. Epoch: 23, mae_loss: 131.94251142, time: 19.90780\n",
      "\n",
      "2021-07-15T03:11:28.780931\n",
      "LR: 0.00011344058379484496\n",
      "[RESULT]: Train. Epoch: 24, mse_loss: 10.40005098, time: 41.36946time: 37.12122\n",
      "[RESULT]: Train. Epoch: 24, mae_loss: 12.57244918, time: 41.38147\n",
      "[RESULT]: Val. Epoch: 24, mse_loss: 12.39882655, time: 19.64398 time: 17.03812\n",
      "[RESULT]: Val. Epoch: 24, mae_loss: 131.61167871, time: 19.65522\n",
      "\n",
      "2021-07-15T03:12:32.450028\n",
      "LR: 0.00011950989295128286\n",
      "[RESULT]: Train. Epoch: 25, mse_loss: 9.81862979, time: 40.67903time: 36.585898\n",
      "[RESULT]: Train. Epoch: 25, mae_loss: 11.40284992, time: 40.68867\n",
      "[RESULT]: Val. Epoch: 25, mse_loss: 11.73476084, time: 19.46419 time: 17.06354\n",
      "[RESULT]: Val. Epoch: 25, mae_loss: 131.67960031, time: 19.47413\n",
      "\n",
      "2021-07-15T03:13:35.038335\n",
      "LR: 0.00012579761259358055\n",
      "[RESULT]: Train. Epoch: 26, mse_loss: 8.62377253, time: 41.34231ime: 36.973568\n",
      "[RESULT]: Train. Epoch: 26, mae_loss: 10.24593589, time: 41.35148\n",
      "[RESULT]: Val. Epoch: 26, mse_loss: 11.57939618, time: 19.09096 time: 16.88070\n",
      "[RESULT]: Val. Epoch: 26, mae_loss: 131.91911970, time: 19.10226\n",
      "\n",
      "2021-07-15T03:14:38.203035\n",
      "LR: 0.00013230031366349667\n",
      "[RESULT]: Train. Epoch: 27, mse_loss: 9.33646645, time: 40.49070time: 36.674618\n",
      "[RESULT]: Train. Epoch: 27, mae_loss: 10.51617404, time: 40.50248\n",
      "[RESULT]: Val. Epoch: 27, mse_loss: 12.05718366, time: 20.74193 time: 18.03978\n",
      "[RESULT]: Val. Epoch: 27, mae_loss: 132.06582642, time: 20.75410\n",
      "\n",
      "2021-07-15T03:15:42.332366\n",
      "LR: 0.0001390144498609481\n",
      "[RESULT]: Train. Epoch: 28, mse_loss: 8.64598366, time: 39.70197time: 35.79078\n",
      "[RESULT]: Train. Epoch: 28, mae_loss: 11.27972419, time: 39.71449\n",
      "[RESULT]: Val. Epoch: 28, mse_loss: 12.21032912, time: 19.02852 time: 16.62621\n",
      "[RESULT]: Val. Epoch: 28, mae_loss: 131.94526091, time: 19.03973\n",
      "\n",
      "2021-07-15T03:16:43.960083\n",
      "LR: 0.00014593635957801173\n",
      "[RESULT]: Train. Epoch: 29, mse_loss: 9.60633437, time: 40.96923time: 36.768758\n",
      "[RESULT]: Train. Epoch: 29, mae_loss: 11.71785616, time: 40.98089\n",
      "[RESULT]: Val. Epoch: 29, mse_loss: 10.82244085, time: 19.13925 time: 16.92366\n",
      "[RESULT]: Val. Epoch: 29, mae_loss: 131.53059860, time: 19.15078\n",
      "\n",
      "2021-07-15T03:17:46.884567\n",
      "LR: 0.00015306226789581234\n",
      "[RESULT]: Train. Epoch: 30, mse_loss: 7.78527992, time: 40.72818time: 36.40078\n",
      "[RESULT]: Train. Epoch: 30, mae_loss: 10.36313286, time: 40.74143\n",
      "[RESULT]: Val. Epoch: 30, mse_loss: 12.22708941, time: 19.91988 time: 17.57715\n",
      "[RESULT]: Val. Epoch: 30, mae_loss: 132.06238156, time: 19.93118\n",
      "\n",
      "2021-07-15T03:18:50.077220\n",
      "LR: 0.00016038828864320517\n",
      "[RESULT]: Train. Epoch: 31, mse_loss: 9.17423410, time: 40.53412time: 35.83802\n",
      "[RESULT]: Train. Epoch: 31, mae_loss: 11.01613939, time: 40.54486\n",
      "[RESULT]: Val. Epoch: 31, mse_loss: 12.36432976, time: 20.07890 time: 17.77864\n",
      "[RESULT]: Val. Epoch: 31, mae_loss: 132.02879297, time: 20.09796\n",
      "\n",
      "2021-07-15T03:19:53.288849\n",
      "LR: 0.00016791042651612966\n",
      "[RESULT]: Train. Epoch: 32, mse_loss: 10.59578827, time: 41.19481time: 36.70405\n",
      "[RESULT]: Train. Epoch: 32, mae_loss: 12.11898695, time: 41.20689\n",
      "[RESULT]: Val. Epoch: 32, mse_loss: 11.12270954, time: 20.23568 time: 17.75813\n",
      "[RESULT]: Val. Epoch: 32, mae_loss: 131.79362451, time: 20.24625\n",
      "\n",
      "2021-07-15T03:20:56.914288\n",
      "LR: 0.00017562457925648098\n",
      "[RESULT]: Train. Epoch: 33, mse_loss: 9.11534975, time: 40.05091time: 35.72969\n",
      "[RESULT]: Train. Epoch: 33, mae_loss: 10.56349620, time: 40.06017\n",
      "[RESULT]: Val. Epoch: 33, mse_loss: 11.33065664, time: 19.90522 time: 17.70870\n",
      "[RESULT]: Val. Epoch: 33, mae_loss: 131.55417270, time: 19.91659\n",
      "\n",
      "2021-07-15T03:21:59.542117\n",
      "LR: 0.0001835265398893093\n",
      "[RESULT]: Train. Epoch: 34, mse_loss: 8.05687066, time: 39.42983time: 35.26282\n",
      "[RESULT]: Train. Epoch: 34, mae_loss: 11.04928652, time: 39.44135\n",
      "[RESULT]: Val. Epoch: 34, mse_loss: 12.93145838, time: 19.49972 time: 17.15052\n",
      "[RESULT]: Val. Epoch: 34, mae_loss: 132.03437297, time: 19.51041\n",
      "\n",
      "2021-07-15T03:23:00.995571\n",
      "LR: 0.00019161199901712733\n",
      "[RESULT]: Train. Epoch: 35, mse_loss: 8.53032062, time: 39.37074time: 35.09571\n",
      "[RESULT]: Train. Epoch: 35, mae_loss: 11.78669914, time: 39.38272\n",
      "[RESULT]: Val. Epoch: 35, mse_loss: 11.60605282, time: 19.83456 time: 17.34404\n",
      "[RESULT]: Val. Epoch: 35, mae_loss: 131.98175594, time: 19.84507\n",
      "\n",
      "2021-07-15T03:24:02.976800\n",
      "LR: 0.00019987654717007442\n",
      "[RESULT]: Train. Epoch: 36, mse_loss: 9.24287918, time: 39.27635time: 35.301794\n",
      "[RESULT]: Train. Epoch: 36, mae_loss: 10.79200193, time: 39.28554\n",
      "[RESULT]: Val. Epoch: 36, mse_loss: 10.42157739, time: 19.68330 time: 17.13382\n",
      "[RESULT]: Val. Epoch: 36, mae_loss: 131.98051489, time: 19.69511\n",
      "\n",
      "2021-07-15T03:25:04.682119\n",
      "LR: 0.0002083156772106562\n",
      "[RESULT]: Train. Epoch: 37, mse_loss: 8.56714973, time: 39.49602time: 35.34952\n",
      "[RESULT]: Train. Epoch: 37, mae_loss: 10.52250356, time: 39.50885\n",
      "[RESULT]: Val. Epoch: 37, mse_loss: 9.32965100, time: 20.37444 time: 17.895153\n",
      "[RESULT]: Val. Epoch: 37, mae_loss: 131.49112956, time: 20.38700\n",
      "\n",
      "2021-07-15T03:26:09.629083\n",
      "LR: 0.0002169247867917488\n",
      "[RESULT]: Train. Epoch: 38, mse_loss: 8.97729533, time: 40.73695time: 36.502334\n",
      "[RESULT]: Train. Epoch: 38, mae_loss: 11.13663510, time: 40.74899\n",
      "[RESULT]: Val. Epoch: 38, mse_loss: 12.13259050, time: 19.34787 time: 16.92028\n",
      "[RESULT]: Val. Epoch: 38, mae_loss: 131.94217319, time: 19.35879\n",
      "\n",
      "2021-07-15T03:27:12.083232\n",
      "LR: 0.0002256991808665251\n",
      "[RESULT]: Train. Epoch: 39, mse_loss: 9.26801034, time: 38.90985time: 34.64813\n",
      "[RESULT]: Train. Epoch: 39, mae_loss: 10.75290466, time: 38.92051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6679:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2f18cc448813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-24d8a5b02420>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mfitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrainGlobalConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#     fitter.load(f'{fitter.base_dir}/last-checkpoint.bin')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-58b9b112908f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0msummary_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[RESULT]: Val. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-58b9b112908f>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(self, val_loader)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mmae_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_pts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=16,\n",
    "        num_workers=16,\n",
    "        shuffle=False,\n",
    "        #sampler=SequentialSampler(valid_dataset),\n",
    "        sampler=val_sampler,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = VGG16_LCM_REG().cuda()\n",
    "test_net = DistributedDataParallel(test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributedDataParallel(\n",
       "  (module): VGG16_LCM_REG(\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (fuse_layer5): DC_layer(\n",
       "      (conv1x1_d1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_d1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv_d2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (conv_d3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (conv_d4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "    )\n",
       "    (fuse_layer4): DC_layer(\n",
       "      (conv1x1_d1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_d1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv_d2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (conv_d3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (conv_d4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "    )\n",
       "    (fuse_layer3): DC_layer(\n",
       "      (conv1x1_d1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1x1_d4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_d1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv_d2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (conv_d3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (conv_d4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "    )\n",
       "    (count_layer5): Count_layer(\n",
       "      (avgpool_layer): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
       "      )\n",
       "      (maxpool_layer): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv1x1): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (count_layer4): Count_layer(\n",
       "      (avgpool_layer): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): AvgPool2d(kernel_size=(4, 4), stride=4, padding=0)\n",
       "      )\n",
       "      (maxpool_layer): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): MaxPool2d(kernel_size=(4, 4), stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv1x1): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (count_layer3): Count_layer(\n",
       "      (avgpool_layer): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): AvgPool2d(kernel_size=(8, 8), stride=8, padding=0)\n",
       "      )\n",
       "      (maxpool_layer): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): MaxPool2d(kernel_size=(8, 8), stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv1x1): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer5_k): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (layer4_k): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (layer3_k): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (layer5_i): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (layer4_i): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (layer3_i): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (layer5_p): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (layer4_p): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (layer3_p): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/AMRNet-7.26-784/best-checkpoint-113epoch.bin')\n",
    "test_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, dmaps, fns, points = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = test_net(imgs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 23, 42])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[379.6073],\n",
       "        [ 66.6977],\n",
       "        [ 33.7065],\n",
       "        [100.8357],\n",
       "        [ 58.4938],\n",
       "        [ 98.8577],\n",
       "        [374.7237],\n",
       "        [ 67.0916],\n",
       "        [359.5981],\n",
       "        [507.7969],\n",
       "        [ 35.8292],\n",
       "        [ 96.5278],\n",
       "        [ 77.5106],\n",
       "        [399.6143],\n",
       "        [ 37.5311],\n",
       "        [ 27.8512]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum(dim=[-1,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[506.0000],\n",
       "        [ 70.0000],\n",
       "        [ 38.0000],\n",
       "        [111.0000],\n",
       "        [ 63.0000],\n",
       "        [126.0000],\n",
       "        [457.0000],\n",
       "        [ 76.0000],\n",
       "        [471.0000],\n",
       "        [532.0000],\n",
       "        [ 28.0000],\n",
       "        [ 93.0000],\n",
       "        [ 86.0000],\n",
       "        [398.0000],\n",
       "        [ 38.0000],\n",
       "        [ 26.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmaps.sum(dim=[-1,-2])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as pnsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmaps: torch.FloatTensor\n",
      "preds: torch.cuda.FloatTensor\n",
      "CPU times: user 5min 58s, sys: 11min 51s, total: 17min 49s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pre_count = []\n",
    "gt_count = []\n",
    "gt_points = []\n",
    "avg_ssim = AverageMeter()\n",
    "avg_pnsr = AverageMeter()\n",
    "kernel6 = 64\n",
    "for step, (imgs, dmaps, fns, points) in enumerate(val_loader):\n",
    "    #with torch.cuda.amp.autocast():\n",
    "    with torch.no_grad():\n",
    "        imgs = imgs.cuda().float()\n",
    "        preds = test_net(imgs)\n",
    "    dmaps = dmaps / LOG_PARA\n",
    "\n",
    "    filter6 = torch.ones(1, 1, kernel6, kernel6, requires_grad=False).float()\n",
    "    dmaps = F.conv2d(dmaps.float(), filter6, stride=kernel6)\n",
    "    \n",
    "    for pred, dmap in zip(preds, dmaps):\n",
    "        pred_array = pred.detach().cpu().numpy().squeeze()\n",
    "        dmap_array = dmap.detach().cpu().numpy().squeeze()\n",
    "        avg_ssim.update(ssim(dmap_array, pred_array, data_range=dmap_array.max()-dmap_array.min()))\n",
    "        avg_pnsr.update(pnsr(dmap_array, pred_array, data_range=dmap_array.max()-dmap_array.min()))\n",
    "    \n",
    "    pre_count.extend(preds.sum(dim=[-1,-2]).detach().cpu().numpy())\n",
    "    \n",
    "    gt_count.extend(dmaps.sum(dim=[-1,-2]).detach().cpu().numpy())\n",
    "    \n",
    "    gt_p = []\n",
    "    for p in points:\n",
    "        gt_p.append(len(p))\n",
    "    gt_points.extend(gt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(pre_count,gt_count)\n",
    "mse = mean_squared_error(pre_count,gt_count)\n",
    "nae = mae * len(pre_count) / np.sum(gt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Paras: 56.424789\n",
      "MAE: 12.378044128417969, MSE: 755.2483520507812, NAE: 0.09548808444236044\n",
      "SSIM: 0.9011724980316669, PNSR: 29.211663611861038\n"
     ]
    }
   ],
   "source": [
    "def count_parameters_in_MB(model):\n",
    "    return np.sum(np.prod(v.size()) for name, v in model.named_parameters() if \"auxiliary\" not in name) / 1e6\n",
    "\n",
    "print(f'#Paras: {count_parameters_in_MB(test_net)}')\n",
    "print(f'MAE: {mae}, MSE: {mse}, NAE: {nae}')\n",
    "print(f'SSIM: {avg_ssim.avg}, PNSR: {avg_pnsr.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
