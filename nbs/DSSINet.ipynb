{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "\n",
    "from loss.ssim_loss import NORMMSSSIM\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import visualize, plot_data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/home/hheat/USERDIR/counting-bench/data'\n",
    "train_images = path + '/images'\n",
    "test_images = path + '/test_images/images'\n",
    "anno = path + '/annotation'\n",
    "density_maps = path + '/dmaps'\n",
    "\n",
    "LOG_PARA = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def fix_shape(image, density_map, n=16):\n",
    "    w = image.shape[-1]\n",
    "    h = image.shape[-2]\n",
    "    padding = [0, 0, 0, 0]\n",
    "    if w % n != 0:\n",
    "        padding[0] = math.ceil(w / n) * n - w\n",
    "    if h % n != 0:\n",
    "        padding[2] = math.ceil(h / n) * n - h\n",
    "    image = F.pad(image, tuple(padding), 'constant', 0)\n",
    "    density_map = F.pad(density_map, tuple(padding), 'constant', 0)\n",
    "    return image, density_map\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            #A.Resize(360,640,interpolation=2),\n",
    "            #A.RandomSizedCrop(min_max_height=(409, 512), height=409, width=512, p=1.0),\n",
    "            #A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=1.0),\n",
    "        ],\n",
    "        #additional_targets={'image': 'image','image1': 'image'}\n",
    "        #keypoint_params = A.KeypointParams(format='xy')\n",
    ")\n",
    "\n",
    "def get_train_image_only_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            #A.Resize(360,640),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "            ],p=0.9),\n",
    "            A.Blur(blur_limit=3,p=0.2),\n",
    "            A.Normalize(mean=mean,std=std,p=1.0,max_pixel_value=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        additional_targets={'image': 'image'}\n",
    "    )\n",
    "\n",
    "def get_valid_trainsforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            #A.Resize(360,640,interpolation=2),\n",
    "            A.Normalize(mean=mean,std=std,p=1.0,max_pixel_value=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# def get_valid_image_only_transforms():\n",
    "#     return A.Compose(\n",
    "#         [\n",
    "#             A.Resize(360,640),\n",
    "#         ],\n",
    "#         additional_targets={'image': 'image'}\n",
    "#     )\n",
    "\n",
    "mean = torch.tensor([0.4939, 0.4794, 0.4583])\n",
    "std = torch.tensor([0.2177, 0.2134, 0.2144])\n",
    "\n",
    "def denormalize(img):\n",
    "    img = img * std[...,None,None] + mean[...,None,None]\n",
    "    img = img.permute(1,2,0).cpu().numpy()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counting_Dataset(Dataset):\n",
    "    def __init__(self,path,image_fnames,dmap_folder,gt_folder=None,transforms=None,mosaic=False,downsample=4):\n",
    "        '''\n",
    "            path: root path \n",
    "            image_fnames: path of images\n",
    "            dmap_folder: density map folder, eg: /dmap\n",
    "            gt_folder: gt folder, currently set to visdrone xml format, modify _get_gt_data() if needed\n",
    "            transforms: iteratable, can be tuple / list ... etc\n",
    "            mosaic: mix up image and density map to form a new image, set to false by default\n",
    "            downsample: resize dmap\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.image_fnames = image_fnames\n",
    "        self.dmap_folder = path + dmap_folder\n",
    "        self.transforms = transforms\n",
    "        self.mosaic = mosaic\n",
    "        self.downsample = downsample\n",
    "        self.gt_folder = gt_folder # test purpose\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_fnames[idx]\n",
    "        \n",
    "        if self.mosaic and random.randint(0,1) < 0.5:\n",
    "            image, density_map, gt_points = self._load_mosaic_image_and_density_map(idx)\n",
    "        else:\n",
    "            image, density_map, gt_points = self._load_image_and_density_map(idx)\n",
    "        \n",
    "        h,w = image.shape[0]//self.downsample, image.shape[1]//self.downsample\n",
    "        image = cv2.resize(image,(w, h))\n",
    "        density_map = cv2.resize(density_map,(w//(self.downsample*2),h//(self.downsample*2)))#,interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Warning: doesn't work for cutout, uncommet transform and make fix code to enable cutout\n",
    "        # Reason: cutout doesn't apply to mask, so mask must be image. check 01a bottom for code\n",
    "        if self.transforms:\n",
    "            for tfms in self.transforms:\n",
    "                aug = tfms(**{\n",
    "                    'image': image,\n",
    "                    'mask': density_map,\n",
    "                    #'keypoints': gt_points\n",
    "                })\n",
    "                #image, density_map, gt_points = aug['image'], aug['mask'], aug['keypoints']\n",
    "                image, density_map = aug['image'], aug['mask'] # issue with previous keypoints (albumentation?)\n",
    "        \n",
    "        \n",
    "        return image, density_map, image_id, gt_points\n",
    "        \n",
    "    \n",
    "    def _get_dmap_name(self,fn):\n",
    "        mask_name = fn.split('/')[-1].split('.')[0]\n",
    "        mask_path = self.dmap_folder + '/' + mask_name + '.npy'\n",
    "        return mask_path\n",
    "    \n",
    "    def _load_image_and_density_map(self,idx):\n",
    "        image_fname = self.image_fnames[idx]\n",
    "        dmap_fname = self._get_dmap_name(image_fname)\n",
    "        image = cv2.imread(image_fname)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = image/255.\n",
    "        d_map = np.load(dmap_fname,allow_pickle=True)\n",
    "        \n",
    "        #sanity check gt\n",
    "        _, points = self._get_gt_data(idx)\n",
    "        # end sanity check\n",
    "        \n",
    "        return image, d_map, points\n",
    "    \n",
    "    def _load_mosaic_image_and_density_map(self,idx):\n",
    "        image_1, dmap_1, points_1 = self._load_image_and_density_map(idx)\n",
    "        while True:\n",
    "            idx_2 = random.randint(0,len(self.image_fnames)-1)\n",
    "            if idx != idx_2:\n",
    "                break\n",
    "        image_2, dmap_2, points_2 = self._load_image_and_density_map(idx_2)\n",
    "        \n",
    "        imsize = min(*image_1.shape[:2])\n",
    "        xc,yc = [int(random.uniform(imsize*0.4,imsize*0.6)) for _ in range(2)]\n",
    "        h,w = image_1.shape[0], image_1.shape[1]\n",
    "\n",
    "        pos = random.randint(0,1)\n",
    "        if pos == 0: #top left\n",
    "            x1a,y1a,x2a,y2a = 0,0,xc,yc # img_1\n",
    "            x1b,y1b,x2b,y2b = w-xc,h-yc,w,h # img_2\n",
    "        elif pos == 1: # top right\n",
    "            x1a,y1a,x2a,y2a = w-xc,0,w,yc\n",
    "            x1b,y1b,x2b,y2b = 0,h-yc,xc,h\n",
    "        elif pos == 2: # bottom left\n",
    "            x1a,y1a,x2a,y2a = 0,h-yc,xc,h\n",
    "            x1b,y1b,x2b,y2b = w-xc,0,w,yc\n",
    "        elif pos == 3: # bottom right\n",
    "            x1a,y1a,x2a,y2a = w-xc,h-yc,w,h\n",
    "            x1b,y1b,x2b,y2b = 0,0,xc,yc\n",
    "        \n",
    "        new_image = image_1.copy()\n",
    "        new_dmap = dmap_1.copy()\n",
    "        new_image[y1a:y2a,x1a:x2a] = image_2[y1b:y2b,x1b:x2b]\n",
    "        new_dmap[y1a:y2a,x1a:x2a] = dmap_2[y1b:y2b,x1b:x2b]\n",
    "        \n",
    "        #TODO: sanity check to see generate gt\n",
    "        \n",
    "        new_gt_points = self._get_mixed_gt_points(points_1,points_2,(x1a,y1a,x2a,y2a),(x1b,y1b,x2b,y2b),(h,w))\n",
    "        \n",
    "        return new_image, new_dmap, new_gt_points\n",
    "    \n",
    "    '''\n",
    "    The follow section blocks are for sanity check \n",
    "    to compare dmap.sum() with gt points\n",
    "    remove if needed\n",
    "    '''\n",
    "    def _get_mixed_gt_points(self,points_1,points_2,img_1_loc, img_2_loc,img_shape):\n",
    "#         fn_1, points_1 = self._get_gt_data(idx_1)\n",
    "#         fn_2, points_2 = self._get_gt_data(idx_2)\n",
    "        x1a,y1a,x2a,y2a = img_1_loc\n",
    "        x1b,y1b,x2b,y2b = img_2_loc\n",
    "        h,w = img_shape\n",
    "        \n",
    "        result_boxes = []\n",
    "        result_boxes.append(points_2)\n",
    "        result_boxes = np.concatenate(result_boxes,0)\n",
    "        padw = x1a-x1b\n",
    "        pady = y1a-y1b\n",
    "\n",
    "        result_boxes[:,0] += padw\n",
    "        result_boxes[:,1] += pady\n",
    "\n",
    "        np.clip(result_boxes[:,0],0,w,out=result_boxes[:,0])\n",
    "        np.clip(result_boxes[:,1],0,h,out=result_boxes[:,1])\n",
    "        result_boxes = result_boxes.astype(np.int32)\n",
    "\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,0] * result_boxes[:,1] > 0)]\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,0] < w)]\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,1] < h)]\n",
    "        \n",
    "        boxes = []\n",
    "        for (x,y) in points_1:\n",
    "            if x >= x1a and x <= x2a and y >= y1a and y <= y2a:\n",
    "                continue\n",
    "            else:\n",
    "                boxes.append((x,y))\n",
    "        if len(boxes) == 0:\n",
    "            return result_boxes\n",
    "        return np.concatenate((boxes, result_boxes),axis=0)\n",
    "    \n",
    "    def _get_gt_data(self,idx):\n",
    "        if not self.gt_folder:\n",
    "            return (None,0)\n",
    "        fn = self.image_fnames[idx]\n",
    "        anno_path = self.path + self.gt_folder + '/' + fn.split('/')[-1].split('.')[0] + '.mat'\n",
    "        test_data = loadmat(anno_path)\n",
    "        points = test_data['annotation'].astype(int)\n",
    "        return fn, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD LOG_PARA to density map\n",
    "\n",
    "class Crop_Dataset(Counting_Dataset):\n",
    "    def __init__(self,path,image_fnames,dmap_folder,gt_folder=None,transforms=None,mosaic=False,downsample=4,crop_size=512,method='train'):\n",
    "        super().__init__(path,image_fnames,dmap_folder,gt_folder,transforms,mosaic,downsample)\n",
    "        self.crop_size = crop_size\n",
    "        if method not in ['train','valid']:\n",
    "            raise Exception('Not Implement')\n",
    "        self.method = method\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        fn = self.image_fnames[idx]\n",
    "        \n",
    "        image,density_map,gt_points = self._load_image_and_density_map(idx)\n",
    "        h,w = image.shape[0], image.shape[1]\n",
    "        #image = cv2.resize(image,(w, h))\n",
    "        \n",
    "        \n",
    "        if self.method == 'train':\n",
    "            #h,w = image.shape[:2]\n",
    "            i,j = self._random_crop(h,w,self.crop_size,self.crop_size)\n",
    "            image = image[i:i+self.crop_size,j:j+self.crop_size]\n",
    "            density_map = density_map[i:i+self.crop_size,j:j+self.crop_size]\n",
    "            \n",
    "            gt_points = gt_points - [j,i]\n",
    "            mask = (gt_points[:,0] >=0 ) * (gt_points[:,0] <= self.crop_size) * (gt_points[:,1]>=0) * (gt_points[:,1]<=self.crop_size)\n",
    "            gt_points = gt_points[mask]\n",
    "            density_map = cv2.resize(density_map,(self.crop_size//self.downsample,self.crop_size//self.downsample))\n",
    "            \n",
    "        else:\n",
    "            image = image[9:-1,:,:]\n",
    "            density_map = cv2.resize(density_map,(w//self.downsample,h//self.downsample))#,interpolation=cv2.INTER_NEAREST)\n",
    "            density_map = density_map[9:-1,:]\n",
    "        \n",
    "        if self.transforms:\n",
    "            for tfms in self.transforms:\n",
    "                aug = tfms(**{\n",
    "                    'image': image,\n",
    "                    'mask': density_map,\n",
    "                    #'keypoints': gt_points\n",
    "                })\n",
    "                #image, density_map, gt_points = aug['image'], aug['mask'], aug['keypoints']\n",
    "                image, density_map = aug['image'], aug['mask'] # issue with previous keypoints (albumentation?)\n",
    "            #image, density_map = fix_shape(image, density_map, 16)\n",
    "        return image, density_map*LOG_PARA, fn, gt_points\n",
    "    \n",
    "    def _random_crop(self, im_h, im_w, crop_h, crop_w):\n",
    "        res_h = im_h - crop_h\n",
    "        res_w = im_w - crop_w\n",
    "        i = random.randint(0, res_h)\n",
    "        j = random.randint(0, res_w)\n",
    "        return i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp = glob(train_images + '/*.jpg')\n",
    "test_fp = glob(test_images + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/home/hheat/USERDIR/counting-bench/data/images/11_233.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/12_240.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/08_113.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/03_319.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/06_176.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/05_105.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/11_204.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/14_253.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/14_129.jpg',\n",
       " '/mnt/home/hheat/USERDIR/counting-bench/data/images/20_248.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(len(train_fp) * 0.8)\n",
    "train_fp[0:split][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Crop_Dataset(path=path,\n",
    "                             image_fnames=train_fp,dmap_folder='/dmaps',\n",
    "                             gt_folder='/annotation',\n",
    "                             transforms=[get_train_transforms(),get_train_image_only_transforms()],\n",
    "                             downsample=1,\n",
    "                             crop_size=784\n",
    "                                )\n",
    "\n",
    "valid_dataset = Crop_Dataset(path=path,\n",
    "                             image_fnames=test_fp,dmap_folder='/dmaps',\n",
    "                             gt_folder='/annotation',\n",
    "                             transforms=[get_valid_trainsforms()],\n",
    "                             method='valid',\n",
    "                             downsample=1,\n",
    "                             crop_size=784\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 32\n",
    "    batch_size = 16\n",
    "    n_epochs = 1 \n",
    "    lr = 0.0002\n",
    "\n",
    "    folder = 'test'\n",
    "    downsample = 1\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = True  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = False  # do scheduler.step after validation stage loss\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "    scheduler_params = dict(\n",
    "        max_lr=1e-4,\n",
    "        #total_steps = len(train_dataset) // 4 * n_epochs, # gradient accumulation\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "        pct_start=0.2,\n",
    "        anneal_strategy='cos', \n",
    "        final_div_factor=10**5\n",
    "    )\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "#     scheduler_params = dict(\n",
    "#         mode='min',\n",
    "#         factor=0.5,\n",
    "#         patience=1,\n",
    "#         verbose=False, \n",
    "#         threshold=0.0001,\n",
    "#         threshold_mode='abs',\n",
    "#         cooldown=0, \n",
    "#         min_lr=1e-8,\n",
    "#         eps=1e-08\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.conv import _ConvNd\n",
    "from torch.nn.modules.utils import _pair\n",
    "from collections import OrderedDict\n",
    "\n",
    "def same_padding_length(input_length, filter_size, stride, dilation=1):\n",
    "    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n",
    "    output_length = (input_length + stride - 1) // stride\n",
    "    pad_length = max(0, (output_length - 1) * stride + dilated_filter_size - input_length)\n",
    "    return pad_length\n",
    "\n",
    "def compute_same_padding2d(input_shape, kernel_size, strides, dilation):\n",
    "    space = input_shape[2:]\n",
    "    assert len(space) == 2, \"{}\".format(space)\n",
    "    new_space = []\n",
    "    new_input = []\n",
    "    for i in range(len(space)):\n",
    "        pad_length = same_padding_length(\n",
    "            space[i],\n",
    "            kernel_size[i],\n",
    "            stride=strides[i],\n",
    "            dilation=dilation[i])\n",
    "        new_space.append(pad_length)\n",
    "        new_input.append(pad_length % 2)\n",
    "    return tuple(new_space), tuple(new_input)\n",
    "\n",
    "class Conv2d_dilated(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, NL='relu', same_padding=False, dilation=1, bn=False, bias=True, groups=1):\n",
    "        super(Conv2d_dilated, self).__init__()\n",
    "        self.conv = _Conv2d_dilated(in_channels, out_channels, kernel_size, 'zeros', stride, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else None\n",
    "        if NL == 'relu' :\n",
    "            self.relu = nn.ReLU(inplace=True) \n",
    "        elif NL == 'prelu':\n",
    "            self.relu = nn.PReLU()\n",
    "        elif NL == 'tanh':\n",
    "            self.relu = nn.Tanh()\n",
    "        elif NL == 'lrelu':\n",
    "            self.relu = nn.LeakyReLU(inplace=True)\n",
    "        elif NL == 'sigmoid':\n",
    "            self.relu = nn.Sigmoid()\n",
    "        else:\n",
    "            self.relu = None\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, x, dilation=None):\n",
    "        x = self.conv(x, dilation)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class _Conv2d_dilated(_ConvNd):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding_mode, stride=1, dilation=1, groups=1, bias=True):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        dilation = _pair(dilation)\n",
    "        super(_Conv2d_dilated, self).__init__(\n",
    "            in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding_mode=padding_mode, \n",
    "            stride=stride, groups=groups, dilation=dilation, bias=bias, padding=_pair(0), output_padding=_pair(0), transposed=False)\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, input, dilation=None):\n",
    "        input_shape = list(input.size())\n",
    "        dilation_rate = self.dilation if dilation is None else _pair(dilation)\n",
    "        padding, pad_input = compute_same_padding2d(input_shape, kernel_size=self.kernel_size, strides=self.stride, dilation=dilation_rate)\n",
    "\n",
    "        if pad_input[0] == 1 or pad_input[1] == 1:\n",
    "            input = F.pad(input, [0, int(pad_input[0]), 0, int(pad_input[1])])\n",
    "        return F.conv2d(input, self.weight, self.bias, self.stride,\n",
    "                       (padding[0] // 2, padding[1] // 2), dilation_rate, self.groups)\n",
    "        #https://github.com/pytorch/pytorch/issues/3867\n",
    "        \n",
    "class SequentialEndpoints(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, endpoints=None):\n",
    "        super(SequentialEndpoints, self).__init__()\n",
    "        assert isinstance(layers, OrderedDict)\n",
    "        for key, module in layers.items():\n",
    "            self.add_module(key, module)\n",
    "        if endpoints is not None:\n",
    "            self.Endpoints = namedtuple('Endpoints', endpoints.values(), verbose=True)\n",
    "            self.endpoints = endpoints\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not (-len(self) <= idx < len(self)):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        if idx < 0:\n",
    "            idx += len(self)\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._modules)\n",
    "\n",
    "    def sub_forward(self, startpoint, endpoint):\n",
    "        def forward(input):\n",
    "            flag = False\n",
    "            for key, module in self._modules.items():\n",
    "                if startpoint == endpoint:\n",
    "                    output = input\n",
    "                    if key == startpoint:\n",
    "                        output = module(output)\n",
    "                        return output\n",
    "                elif flag or key == startpoint:\n",
    "                    if key == startpoint:\n",
    "                        output = input\n",
    "                    flag = True\n",
    "                    output = module(output)\n",
    "                    if key == endpoint:\n",
    "                        return output\n",
    "            return output\n",
    "        return forward\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, input, require_endpoints=False):\n",
    "        if require_endpoints:\n",
    "            endpoints = self.Endpoints([None] * len(self.endpoints.keys()))\n",
    "        for key, module in self._modules.items():\n",
    "            input = module(input)\n",
    "            if require_endpoints and key in self.endpoints.keys():\n",
    "                setattr(endpoints, self.endpoints[key], input)\n",
    "        if require_endpoints:\n",
    "            return input, endpoints\n",
    "        else:\n",
    "            return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#model_urls = {\n",
    "#    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "#    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "#    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "#    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "#    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "#    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "#    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "#    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "#}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False, output_stride=8, base_dilated_rate=1, NL='relu', bias=True):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    layers = OrderedDict()\n",
    "    idx = 0\n",
    "    curr_stride = 1\n",
    "    dilated_rate = base_dilated_rate\n",
    "    for v in cfg:\n",
    "        name, ks, padding = str(idx), (3, 3), (1, 1)\n",
    "        if type(v) is tuple:\n",
    "            if len(v) == 2:\n",
    "                v, ks = v\n",
    "            elif len(v) == 3:\n",
    "                name, v, ks = v\n",
    "            elif len(v) == 4:\n",
    "                name, v, ks, padding = v\n",
    "        if v == 'M':\n",
    "            if curr_stride >= output_stride:\n",
    "                dilated_rate = 2\n",
    "                curr_stride *= 2\n",
    "            else:\n",
    "                layers[name] = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=False)\n",
    "                curr_stride *= 2\n",
    "            idx += 1\n",
    "        elif v == 'None':\n",
    "            idx += 1\n",
    "        else:\n",
    "            # conv2d = _Conv2d_dilated(in_channels, v, dilation=dilated_rate, kernel_size=ks, bias=bias)\n",
    "            conv2d = nn.Conv2d(in_channels, v, dilation=dilated_rate, kernel_size=ks, padding=padding, bias=bias)\n",
    "            dilated_rate = base_dilated_rate\n",
    "            layers[name] = conv2d\n",
    "            idx += 1\n",
    "            if batch_norm:\n",
    "                layers[str(idx)] = nn.BatchNorm2d(v)\n",
    "                idx += 1\n",
    "            if NL == 'relu' :\n",
    "                relu = nn.ReLU(inplace=True)\n",
    "            if NL == 'nrelu' :\n",
    "                relu = nn.ReLU(inplace=False)\n",
    "            elif NL == 'prelu':\n",
    "                relu = nn.PReLU()\n",
    "            layers['relu'+str(idx)] = relu\n",
    "            idx += 1\n",
    "            in_channels = v\n",
    "    print(\"\\n\".join([\"{}: {}-{}\".format(i, k, v) for i, (k,v) in enumerate(layers.items())]))\n",
    "    return SequentialEndpoints(layers)\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'F': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512],\n",
    "    'G': [64, 64, 'M', 128, 128, 'M', 256, 256, 256],\n",
    "    'H': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'None', 512, 512, 512, 'None', 512, 512, 512],\n",
    "    'I': [24, 22, 'M', 41, 51, 'M', 108, 89, 111, 'M', 184, 276, 228],\n",
    "}\n",
    "\n",
    "def vgg16(struct='F', **kwargs):\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfg[struct], **kwargs))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "## CRFFeatureRF\n",
    "class MessagePassing(nn.Module):\n",
    "    def __init__(self, branch_n, input_ncs, bn=False):\n",
    "        super(MessagePassing, self).__init__()\n",
    "        self.branch_n = branch_n\n",
    "        self.iters = 2\n",
    "        for i in range(branch_n):\n",
    "            for j in range(branch_n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                setattr(self, \"w_0_{}_{}_0\".format(j, i), \\\n",
    "                        nn.Sequential(\n",
    "                                Conv2d_dilated(input_ncs[j],  input_ncs[i], 1, dilation=1, same_padding=True, NL=None, bn=bn),\n",
    "                            )\n",
    "                        )\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.prelu = nn.PReLU()\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, input):\n",
    "        hidden_state = input\n",
    "        side_state = []\n",
    "\n",
    "        for _ in range(self.iters):\n",
    "            hidden_state_new = []\n",
    "            for i in range(self.branch_n):\n",
    "\n",
    "                unary = hidden_state[i]\n",
    "                binary = None\n",
    "                for j in range(self.branch_n):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    if binary is None:\n",
    "                        binary = getattr(self, 'w_0_{}_{}_0'.format(j, i))(hidden_state[j])\n",
    "                    else:\n",
    "                        binary = binary + getattr(self, 'w_0_{}_{}_0'.format(j, i))(hidden_state[j])\n",
    "\n",
    "                binary = self.prelu(binary)\n",
    "                hidden_state_new += [self.relu(unary + binary)]\n",
    "            hidden_state = hidden_state_new\n",
    "\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFVGG(nn.Module):\n",
    "    def __init__(self, output_stride=8, bn=False):\n",
    "        super(CRFVGG, self).__init__()\n",
    "\n",
    "        self.output_stride = output_stride\n",
    "\n",
    "        self.pyramid = [2, 0.5]\n",
    "\n",
    "        self.front_end = vgg16(struct='F', NL=\"prelu\", output_stride=self.output_stride)\n",
    "\n",
    "\n",
    "        self.passing1 = MessagePassing( branch_n=2, \n",
    "                                        input_ncs=[128, 64],\n",
    "                                        )\n",
    "        self.passing2 = MessagePassing( branch_n=3, \n",
    "                                        input_ncs=[256, 128, 64],\n",
    "                                        )\n",
    "        self.passing3 = MessagePassing( branch_n=3, \n",
    "                                        input_ncs=[512, 256, 128]\n",
    "                                        )\n",
    "        self.passing4 = MessagePassing( branch_n=2, \n",
    "                                        input_ncs=[512, 256]\n",
    "                                        )\n",
    "\n",
    "\n",
    "        self.decoder1 = nn.Sequential(\n",
    "                Conv2d_dilated(512, 128,   1, dilation=1, same_padding=True, NL='relu', bn=bn),\n",
    "                Conv2d_dilated(128,   1,   3, dilation=1, same_padding=True, NL=None, bn=bn),\n",
    "            )\n",
    "\n",
    "        self.decoder2 = nn.Sequential(\n",
    "                Conv2d_dilated(768, 128,   1, dilation=1, same_padding=True, NL='relu', bn=bn),\n",
    "                Conv2d_dilated(128,   1,   3, dilation=1, same_padding=True, NL=None, bn=bn),\n",
    "            )\n",
    "\n",
    "        self.decoder3 = nn.Sequential(\n",
    "                Conv2d_dilated(896, 128,   1, dilation=1, same_padding=True, NL='relu', bn=bn),\n",
    "                Conv2d_dilated(128,   1,   3, dilation=1, same_padding=True, NL=None, bn=bn),\n",
    "            )\n",
    "\n",
    "        self.decoder4 = nn.Sequential(\n",
    "                Conv2d_dilated(448, 128,   1, dilation=1, same_padding=True, NL='relu', bn=bn),\n",
    "                Conv2d_dilated(128,   1,   3, dilation=1, same_padding=True, NL=None, bn=bn),\n",
    "            )\n",
    "\n",
    "        self.decoder5 = nn.Sequential(\n",
    "                Conv2d_dilated(192, 128,   1, dilation=1, same_padding=True, NL='relu', bn=bn),\n",
    "                Conv2d_dilated(128,   1,   3, dilation=1, same_padding=True, NL=None, bn=bn),\n",
    "            )\n",
    "\n",
    "        self.passing_weight1 = Conv2d_dilated(1,  1, 3, same_padding=True, NL=None, bn=bn)\n",
    "        self.passing_weight2 = Conv2d_dilated(1,  1, 3, same_padding=True, NL=None, bn=bn)\n",
    "        self.passing_weight3 = Conv2d_dilated(1,  1, 3, same_padding=True, NL=None, bn=bn)\n",
    "        self.passing_weight4 = Conv2d_dilated(1,  1, 3, same_padding=True, NL=None, bn=bn)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, im_data, return_feature=False):\n",
    "        conv1_2 = ['0', 'relu3']\n",
    "        conv1_2_na = ['0', '2']\n",
    "        conv2_2 = ['4', 'relu8']\n",
    "        conv2_2_na = ['4', '7']\n",
    "        conv3_3 = ['9', 'relu15']\n",
    "        conv3_3_na = ['9', '14']\n",
    "        # layer 16 is the max pooling layer\n",
    "        conv4_3 = ['16', 'relu22']\n",
    "        conv4_3_na = ['16', '21']\n",
    "        # droping the last pooling layer, 17 would become dilated with rate 2\n",
    "        # conv4_3 = ['17', 'relu22']\n",
    "\n",
    "        batch_size, C, H, W = im_data.shape\n",
    "\n",
    "        with torch.no_grad():\n",
    "            im_scale1 = nn.functional.upsample(im_data, size=(int(H * self.pyramid[0]), int(W * self.pyramid[0])), align_corners=False, mode=\"bilinear\")\n",
    "            im_scale2 = im_data\n",
    "            im_scale3 = nn.functional.upsample(im_data, size=(int(H * self.pyramid[1]), int(W * self.pyramid[1])), align_corners=False, mode=\"bilinear\")\n",
    "\n",
    "\n",
    "        mp_scale1_feature_conv2_na = self.front_end.features.sub_forward(conv1_2[0], conv2_2_na[1])(im_scale1)\n",
    "        mp_scale2_feature_conv1_na = self.front_end.features.sub_forward(*conv1_2_na)(im_scale2)\n",
    "\n",
    "        mp_scale1_feature_conv2, mp_scale2_feature_conv1 \\\n",
    "                        = self.passing1([mp_scale1_feature_conv2_na, mp_scale2_feature_conv1_na])\n",
    "\n",
    "\n",
    "        aggregation4 = torch.cat([mp_scale1_feature_conv2, mp_scale2_feature_conv1], dim=1)\n",
    "\n",
    "        mp_scale1_feature_conv3_na = self.front_end.features.sub_forward(*conv3_3_na)(mp_scale1_feature_conv2)\n",
    "        mp_scale2_feature_conv2_na = self.front_end.features.sub_forward(*conv2_2_na)(mp_scale2_feature_conv1)\n",
    "        mp_scale3_feature_conv1_na = self.front_end.features.sub_forward(*conv1_2_na)(im_scale3)\n",
    "\n",
    "\n",
    "        mp_scale1_feature_conv3, mp_scale2_feature_conv2, mp_scale3_feature_conv1 \\\n",
    "                        = self.passing2([mp_scale1_feature_conv3_na, mp_scale2_feature_conv2_na, mp_scale3_feature_conv1_na])\n",
    "        aggregation3 = torch.cat([mp_scale1_feature_conv3, mp_scale2_feature_conv2, mp_scale3_feature_conv1], dim=1)\n",
    "\n",
    "\n",
    "        mp_scale1_feature_conv4_na = self.front_end.features.sub_forward(*conv4_3_na)(mp_scale1_feature_conv3)\n",
    "        mp_scale2_feature_conv3_na = self.front_end.features.sub_forward(*conv3_3_na)(mp_scale2_feature_conv2)\n",
    "        mp_scale3_feature_conv2_na = self.front_end.features.sub_forward(*conv2_2_na)(mp_scale3_feature_conv1)\n",
    "\n",
    "        mp_scale1_feature_conv4, mp_scale2_feature_conv3, mp_scale3_feature_conv2 \\\n",
    "                        = self.passing3([mp_scale1_feature_conv4_na, mp_scale2_feature_conv3_na, mp_scale3_feature_conv2_na])\n",
    "        aggregation2 = torch.cat([mp_scale1_feature_conv4, mp_scale2_feature_conv3, mp_scale3_feature_conv2], dim=1)\n",
    "\n",
    "        mp_scale2_feature_conv4_na = self.front_end.features.sub_forward(*conv4_3_na)(mp_scale2_feature_conv3)\n",
    "        mp_scale3_feature_conv3_na = self.front_end.features.sub_forward(*conv3_3_na)(mp_scale3_feature_conv2)\n",
    "\n",
    "        mp_scale2_feature_conv4, mp_scale3_feature_conv3 \\\n",
    "                        = self.passing4([mp_scale2_feature_conv4_na, mp_scale3_feature_conv3_na])\n",
    "        aggregation1 = torch.cat([mp_scale2_feature_conv4, mp_scale3_feature_conv3], dim=1)\n",
    "\n",
    "        mp_scale3_feature_conv4 = self.front_end.features.sub_forward(*conv4_3)(mp_scale3_feature_conv3)\n",
    "\n",
    "        dens1 = self.decoder1(mp_scale3_feature_conv4)\n",
    "        dens2 = self.decoder2(aggregation1)\n",
    "        dens3 = self.decoder3(aggregation2)\n",
    "        dens4 = self.decoder4(aggregation3)\n",
    "        dens5 = self.decoder5(aggregation4)\n",
    "        #print(dens1.shape, dens2.shape, dens3.shape, dens4.shape, dens5.shape)\n",
    "        dens1 = self.prelu(dens1)\n",
    "        dens2 = self.prelu(dens2 + self.passing_weight1(nn.functional.upsample(dens1, scale_factor=2, align_corners=False, mode=\"bilinear\")))\n",
    "        dens3 = self.prelu(dens3 + self.passing_weight2(nn.functional.upsample(dens2, scale_factor=2, align_corners=False, mode=\"bilinear\")))\n",
    "        dens4 = self.prelu(dens4 + self.passing_weight3(nn.functional.upsample(dens3, scale_factor=2, align_corners=False, mode=\"bilinear\")))\n",
    "        dens5 = self.relu(dens5 + self.passing_weight4(nn.functional.upsample(dens4, scale_factor=2, align_corners=False, mode=\"bilinear\")))\n",
    "\n",
    "        return dens5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0-Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "1: relu1-PReLU(num_parameters=1)\n",
      "2: 2-Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "3: relu3-PReLU(num_parameters=1)\n",
      "4: 4-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "5: 5-Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "6: relu6-PReLU(num_parameters=1)\n",
      "7: 7-Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "8: relu8-PReLU(num_parameters=1)\n",
      "9: 9-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "10: 10-Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "11: relu11-PReLU(num_parameters=1)\n",
      "12: 12-Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "13: relu13-PReLU(num_parameters=1)\n",
      "14: 14-Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "15: relu15-PReLU(num_parameters=1)\n",
      "16: 16-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "17: 17-Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "18: relu18-PReLU(num_parameters=1)\n",
      "19: 19-Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "20: relu20-PReLU(num_parameters=1)\n",
      "21: 21-Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "22: relu22-PReLU(num_parameters=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/zpengac/.Miniconda3/envs/f4774e49c9ffe87fb0928ec97f8ff682/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "img, dmap, fn, points = valid_dataset[250]\n",
    "mm = CRFVGG()\n",
    "pred = mm(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1520, 2720])\n"
     ]
    }
   ],
   "source": [
    "mm.eval()\n",
    "pred=mm(img.unsqueeze(0))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss_DSSI(preds, targs):\n",
    "    return NORMMSSSIM()(preds,targs)\n",
    "\n",
    "def MSELoss_MCNN(preds,targs):\n",
    "    return nn.MSELoss()(preds,targs)\n",
    "\n",
    "def MAELoss_MCNN(preds,targs,upsample):\n",
    "    return nn.L1Loss()((preds/LOG_PARA).sum(dim=[-1,-2])*upsample*upsample, (targs/LOG_PARA).sum(dim=[-1,-2])*upsample*upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#opt_level ='O1' # apex\n",
    "\n",
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10**5\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        \n",
    "        #self.model, self.optimizer = amp.initialize(self.model,self.optimizer,opt_level=opt_level) # apex\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.criterion = SSIMLoss_DSSI\n",
    "        self.metric = MAELoss_MCNN\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "        \n",
    "        # self.iters_to_accumulate = 4 # gradient accumulation\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, mae_loss = self.train_one_epoch(train_loader)\n",
    "            self.log(f'[DEBUG]: val: {summary_loss.val}, total: {summary_loss.sum}, count: {summary_loss.count}')\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, mae_loss: {mae_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, mae_loss = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, mae_loss: {mae_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        mae_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, density_maps, fns, gt_pts) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'mse_loss: {summary_loss.avg:.8f}, ' + \\\n",
    "                        f'mae_loss: {mae_loss.avg:.8f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.cuda().float()\n",
    "                density_maps = density_maps.cuda().float()\n",
    "                \n",
    "\n",
    "                #preds = self.model(images)\n",
    "                with torch.cuda.amp.autocast(): #native fp16\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds,density_maps)\n",
    "                    metric_loss = self.metric(preds,density_maps,self.config.downsample)\n",
    "                mae_loss.update(metric_loss.detach().item(),batch_size)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "                \n",
    "            if step == 20:\n",
    "                break\n",
    "\n",
    "        return summary_loss, mae_loss\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        mae_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, density_maps, fns, gt_pts) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'mse_loss: {summary_loss.avg:.8f}, ' + \\\n",
    "                        f'mae_loss: {mae_loss.avg:.8f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            \n",
    "            images = images.cuda().float()\n",
    "            batch_size = images.shape[0]\n",
    "            density_maps = density_maps.cuda().float()\n",
    "            \n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast(): #native fp16\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds,density_maps)\n",
    "                #print(f'loss: {loss}, loss_item: {loss.detach().item()}')\n",
    "                metric_loss = self.metric(preds.detach(),density_maps.detach(),self.config.downsample)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            # loss = loss / self.iters_to_accumulate # gradient accumulation\n",
    "            \n",
    "#             with amp.scale_loss(loss,self.optimizer) as scaled_loss: # apex\n",
    "#                 scaled_loss.backward()\n",
    "            #loss.backward()\n",
    "\n",
    "            \n",
    "            mae_loss.update(metric_loss.detach().item(),batch_size)\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "            \n",
    "            #self.optimizer.step()\n",
    "            self.scaler.step(self.optimizer) # native fp16\n",
    "            \n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            self.scaler.update() #native fp16\n",
    "                \n",
    "                \n",
    "#             if (step+1) % self.iters_to_accumulate == 0: # gradient accumulation\n",
    "\n",
    "#                 self.optimizer.step()\n",
    "#                 self.optimizer.zero_grad()\n",
    "\n",
    "#                 if self.config.step_scheduler:\n",
    "#                     self.scheduler.step()\n",
    "                    \n",
    "            if step == 20:\n",
    "                break\n",
    "\n",
    "        return summary_loss, mae_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_summary_loss': self.best_summary_loss,\n",
    "            'epoch': self.epoch,\n",
    "            #'amp': amp.state_dict() # apex\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
    "        self.epoch = checkpoint['epoch'] + 1\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_init(host_addr, rank, local_rank, world_size, port=23456):\n",
    "    host_addr_full = 'tcp://' + host_addr + ':' + str(port)\n",
    "    torch.distributed.init_process_group(\"gloo\", init_method=host_addr_full,\n",
    "                                         rank=rank, world_size=world_size)\n",
    "    assert torch.distributed.is_initialized()\n",
    "    \n",
    "def get_ip(iplist):\n",
    "        ip = iplist.split('[')[0] + iplist.split('[')[1].split('-')[0]\n",
    "        return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-0-1-10 0 0 1\n"
     ]
    }
   ],
   "source": [
    "rank = int(os.environ['SLURM_PROCID'])\n",
    "local_rank = int(os.environ['SLURM_LOCALID'])\n",
    "world_size = int(os.environ['SLURM_NTASKS'])\n",
    "iplist = os.environ['SLURM_JOB_NODELIST']\n",
    "#ip = get_ip(iplist)\n",
    "print(iplist, rank, local_rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_init(iplist, rank, local_rank, world_size, 23457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "val_sampler = DistributedSampler(valid_dataset, num_replicas=world_size, rank=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs, dmaps, fns, gt_points = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    dmaps = torch.stack(dmaps).unsqueeze(1)\n",
    "    return imgs,dmaps,fns,gt_points\n",
    "\n",
    "def run_training():\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        #sampler=RandomSampler(train_dataset),\n",
    "        sampler=train_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size//4,\n",
    "        num_workers=TrainGlobalConfig.num_workers//2,\n",
    "        shuffle=False,\n",
    "        #sampler=SequentialSampler(valid_dataset),\n",
    "        sampler=val_sampler,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "#     fitter.load(f'{fitter.base_dir}/last-checkpoint.bin')\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0-Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "1: relu1-PReLU(num_parameters=1)\n",
      "2: 2-Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "3: relu3-PReLU(num_parameters=1)\n",
      "4: 4-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "5: 5-Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "6: relu6-PReLU(num_parameters=1)\n",
      "7: 7-Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "8: relu8-PReLU(num_parameters=1)\n",
      "9: 9-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "10: 10-Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "11: relu11-PReLU(num_parameters=1)\n",
      "12: 12-Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "13: relu13-PReLU(num_parameters=1)\n",
      "14: 14-Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "15: relu15-PReLU(num_parameters=1)\n",
      "16: 16-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "17: 17-Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "18: relu18-PReLU(num_parameters=1)\n",
      "19: 19-Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "20: relu20-PReLU(num_parameters=1)\n",
      "21: 21-Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "22: relu22-PReLU(num_parameters=1)\n"
     ]
    }
   ],
   "source": [
    "net = CRFVGG().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DistributedDataParallel(net, find_unused_parameters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/DSSINet-7.19/best-checkpoint-126epoch.bin')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2021-08-20T03:21:02.766739\n",
      "LR: 4.000000000000002e-06\n",
      "0.9625648260116577, 0.9612278342247009, 0.9545122385025024, 0.941596508026123, 0.949341356754303\n",
      "0.9667537808418274, 0.9657262563705444, 0.9604282975196838, 0.9470486640930176, 0.9537469148635864\n",
      "0.9396904706954956, 0.9375836849212646, 0.9270009398460388, 0.9019054174423218, 0.9132164120674133\n",
      "0.9450084567070007, 0.9425106048583984, 0.9313231706619263, 0.9096148014068604, 0.9123526811599731\n",
      "0.9314364790916443, 0.9288691878318787, 0.915503740310669, 0.8715795874595642, 0.8634461760520935\n",
      "0.9589022994041443, 0.9571607112884521, 0.9499714374542236, 0.9429653882980347, 0.9521145820617676\n",
      "0.9539933800697327, 0.9522859454154968, 0.9432856440544128, 0.917532742023468, 0.9250395894050598\n",
      "0.9401646852493286, 0.9370766282081604, 0.9240169525146484, 0.8995863199234009, 0.9073211550712585\n",
      "0.980847954750061, 0.9800903797149658, 0.9768407940864563, 0.9755904078483582, 0.9820631146430969\n",
      "0.9387836456298828, 0.9378774762153625, 0.9316654205322266, 0.906517744064331, 0.9196872115135193\n",
      "0.9417253136634827, 0.938858687877655, 0.9260030388832092, 0.8939461708068848, 0.8963936567306519\n",
      "0.9242475628852844, 0.9227212071418762, 0.9139674305915833, 0.8853976726531982, 0.8914356231689453\n",
      "0.9194324612617493, 0.9179377555847168, 0.9082192778587341, 0.8662399053573608, 0.8655211329460144\n",
      "0.9081730246543884, 0.9049164056777954, 0.8870496153831482, 0.8310223817825317, 0.8275056481361389\n",
      "0.9618212580680847, 0.9615022540092468, 0.9575945734977722, 0.9412634968757629, 0.9458876252174377\n",
      "0.9602853059768677, 0.9593016505241394, 0.9530609250068665, 0.9362967014312744, 0.9445602297782898\n",
      "0.9365677833557129, 0.9342052936553955, 0.9216094017028809, 0.8936932682991028, 0.900394082069397\n",
      "0.9678379893302917, 0.9660685062408447, 0.958043098449707, 0.9462792277336121, 0.9532040953636169\n",
      "0.905911386013031, 0.904028058052063, 0.8899015188217163, 0.8436323404312134, 0.8422629833221436\n",
      "0.9466927647590637, 0.9466793537139893, 0.9399635791778564, 0.916763186454773, 0.9220400452613831\n",
      "0.9314850568771362, 0.9303578734397888, 0.9205319881439209, 0.8868565559387207, 0.884604275226593\n",
      "[DEBUG]: val: 0.08913731575012207, total: 24.500285148620605, count: 336\n",
      "[RESULT]: Train. Epoch: 0, mse_loss: 0.07291752, time: 33.95494\n",
      "[RESULT]: Train. Epoch: 0, mae_loss: 24.88528924, time: 33.95739\n",
      "0.9739475250244141, 0.97182697057724, 0.9631139636039734, 0.9506665468215942, 0.9521250128746033\n",
      "0.9781768321990967, 0.9767757654190063, 0.9718281030654907, 0.9668141603469849, 0.9682385921478271\n",
      "0.962725043296814, 0.9604983925819397, 0.9527531266212463, 0.9451009631156921, 0.945989727973938\n",
      "0.9713672995567322, 0.970099687576294, 0.9642044901847839, 0.951191246509552, 0.9470210075378418\n",
      "0.9747368097305298, 0.9734534621238708, 0.9673109650611877, 0.9566812515258789, 0.9570399522781372\n",
      "0.9910663962364197, 0.9908602833747864, 0.9896752834320068, 0.9890236258506775, 0.9907730221748352\n",
      "0.9762208461761475, 0.9744774103164673, 0.9680773019790649, 0.9597762823104858, 0.9598466753959656\n",
      "0.9513164162635803, 0.952940046787262, 0.9503127336502075, 0.9258404970169067, 0.8961327075958252\n",
      "0.9561725854873657, 0.9570594429969788, 0.9533858895301819, 0.9298726916313171, 0.9188005328178406\n",
      "0.9886302351951599, 0.9874579906463623, 0.9836242198944092, 0.9815990328788757, 0.9839740991592407\n",
      "0.9794718623161316, 0.9776713848114014, 0.9726486206054688, 0.9698383212089539, 0.9724424481391907\n",
      "0.965984582901001, 0.9643967747688293, 0.9572070240974426, 0.9412389993667603, 0.9375792145729065\n",
      "0.9782235026359558, 0.9778150320053101, 0.9744789004325867, 0.9645231366157532, 0.9664218425750732\n",
      "0.9756262898445129, 0.9739570617675781, 0.9671859741210938, 0.9581137299537659, 0.9596764445304871\n",
      "0.9712455868721008, 0.9697877764701843, 0.96258544921875, 0.9452714920043945, 0.9386098980903625\n",
      "0.9576283693313599, 0.9577736854553223, 0.9524640440940857, 0.9250490665435791, 0.9143982529640198\n",
      "0.9589137434959412, 0.9579687714576721, 0.9509146213531494, 0.9237524271011353, 0.9144456386566162\n",
      "0.976314127445221, 0.9764322638511658, 0.9741104245185852, 0.9633363485336304, 0.9640876650810242\n",
      "0.9420152902603149, 0.9403772354125977, 0.931637167930603, 0.9119491577148438, 0.9071348905563354\n",
      "0.9713810086250305, 0.9695642590522766, 0.961754560470581, 0.9494137167930603, 0.9479938745498657\n",
      "0.9858332276344299, 0.9847015142440796, 0.9811004996299744, 0.9800003170967102, 0.9829798340797424\n",
      "[RESULT]: Val. Epoch: 0, mse_loss: 0.03889231, time: 20.64679\n",
      "[RESULT]: Val. Epoch: 0, mae_loss: 135.50953293, time: 20.65520\n"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=2,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "        #sampler=SequentialSampler(valid_dataset),\n",
    "        sampler=val_sampler,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0-Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "1: relu1-PReLU(num_parameters=1)\n",
      "2: 2-Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "3: relu3-PReLU(num_parameters=1)\n",
      "4: 4-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "5: 5-Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "6: relu6-PReLU(num_parameters=1)\n",
      "7: 7-Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "8: relu8-PReLU(num_parameters=1)\n",
      "9: 9-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "10: 10-Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "11: relu11-PReLU(num_parameters=1)\n",
      "12: 12-Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "13: relu13-PReLU(num_parameters=1)\n",
      "14: 14-Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "15: relu15-PReLU(num_parameters=1)\n",
      "16: 16-MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "17: 17-Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "18: relu18-PReLU(num_parameters=1)\n",
      "19: 19-Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "20: relu20-PReLU(num_parameters=1)\n",
      "21: 21-Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "22: relu22-PReLU(num_parameters=1)\n"
     ]
    }
   ],
   "source": [
    "test_net = CRFVGG().cuda()\n",
    "test_net = DistributedDataParallel(test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributedDataParallel(\n",
       "  (module): CRFVGG(\n",
       "    (front_end): VGG(\n",
       "      (features): SequentialEndpoints(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu1): PReLU(num_parameters=1)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu3): PReLU(num_parameters=1)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu6): PReLU(num_parameters=1)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu8): PReLU(num_parameters=1)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu11): PReLU(num_parameters=1)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu13): PReLU(num_parameters=1)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu15): PReLU(num_parameters=1)\n",
       "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu18): PReLU(num_parameters=1)\n",
       "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu20): PReLU(num_parameters=1)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu22): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (passing1): MessagePassing(\n",
       "      (w_0_1_0_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_0_1_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (passing2): MessagePassing(\n",
       "      (w_0_1_0_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_2_0_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_0_1_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_2_1_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_0_2_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_1_2_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (passing3): MessagePassing(\n",
       "      (w_0_1_0_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_2_0_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_0_1_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_2_1_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_0_2_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_1_2_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (passing4): MessagePassing(\n",
       "      (w_0_1_0_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (w_0_0_1_0): Sequential(\n",
       "        (0): Conv2d_dilated(\n",
       "          (conv): _Conv2d_dilated(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (decoder1): Sequential(\n",
       "      (0): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (decoder2): Sequential(\n",
       "      (0): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (decoder3): Sequential(\n",
       "      (0): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(896, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (decoder4): Sequential(\n",
       "      (0): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(448, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (decoder5): Sequential(\n",
       "      (0): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d_dilated(\n",
       "        (conv): _Conv2d_dilated(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (passing_weight1): Conv2d_dilated(\n",
       "      (conv): _Conv2d_dilated(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (passing_weight2): Conv2d_dilated(\n",
       "      (conv): _Conv2d_dilated(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (passing_weight3): Conv2d_dilated(\n",
       "      (conv): _Conv2d_dilated(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (passing_weight4): Conv2d_dilated(\n",
       "      (conv): _Conv2d_dilated(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (prelu): PReLU(num_parameters=1)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/DSSINet-7.19-784/best-checkpoint-126epoch.bin')\n",
    "test_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, dmaps, fns, points = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    imgs = imgs.cuda().float()\n",
    "    preds = test_net(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0717, device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSIMLoss_DSSI(preds.float(), dmaps.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as pnsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [1:06:09<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 38s, sys: 26min 17s, total: 1h 7min 55s\n",
      "Wall time: 1h 6min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pre_count = []\n",
    "gt_count = []\n",
    "gt_points = []\n",
    "avg_ssim = AverageMeter()\n",
    "avg_pnsr = AverageMeter()\n",
    "for imgs, dmaps, fns, points in tqdm(val_loader):\n",
    "    with torch.no_grad():\n",
    "        imgs = imgs.cuda().float()\n",
    "        preds = test_net(imgs) / LOG_PARA\n",
    "    dmaps = dmaps / LOG_PARA\n",
    "    \n",
    "    for pred, dmap in zip(preds, dmaps):\n",
    "        pred_array = pred.detach().cpu().numpy().squeeze()\n",
    "        dmap_array = dmap.detach().cpu().numpy().squeeze()\n",
    "        avg_ssim.update(ssim(dmap_array, pred_array, data_range=dmap_array.max()-dmap_array.min()))\n",
    "        avg_pnsr.update(pnsr(dmap_array, pred_array, data_range=dmap_array.max()-dmap_array.min()))\n",
    "    \n",
    "    pre_count.extend(preds.sum(dim=[-1,-2]).detach().cpu().numpy())\n",
    "    \n",
    "    gt_count.extend(dmaps.sum(dim=[-1,-2]).detach().cpu().numpy())\n",
    "    \n",
    "    gt_p = []\n",
    "    for p in points:\n",
    "        gt_p.append(len(p))\n",
    "    gt_points.extend(gt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(pre_count,gt_count)\n",
    "mse = mean_squared_error(pre_count,gt_count)\n",
    "nae = mae * len(pre_count) / np.sum(gt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Paras: 8.857788\n",
      "MAE: 13.951478958129883, MSE: 541.29296875, NAE: 0.10652390475746455\n",
      "SSIM: 0.9663761205528096, PNSR: 40.11231028603635\n"
     ]
    }
   ],
   "source": [
    "def count_parameters_in_MB(model):\n",
    "    return np.sum(np.prod(v.size()) for name, v in model.named_parameters() if \"auxiliary\" not in name) / 1e6\n",
    "\n",
    "print(f'#Paras: {count_parameters_in_MB(test_net)}')\n",
    "print(f'MAE: {mae}, MSE: {mse}, NAE: {nae}')\n",
    "print(f'SSIM: {avg_ssim.avg}, PNSR: {avg_pnsr.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
