{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import visualize, plot_data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/home/zpengac/USERDIR/count/drone_dataset'\n",
    "#train_images = path + '/images'\n",
    "#test_images = path + '/test_images/images'\n",
    "#anno = path + '/annotation'\n",
    "images = path + '/rf_image_vehicle'\n",
    "density_maps = path + '/rf_GT_vehicle'\n",
    "\n",
    "LOG_PARA = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            #A.Resize(360,640,interpolation=2),\n",
    "            #A.RandomSizedCrop(min_max_height=(409, 512), height=409, width=512, p=1.0),\n",
    "            #A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=1.0),\n",
    "        ],\n",
    "        #additional_targets={'image': 'image','image1': 'image'}\n",
    "        #keypoint_params = A.KeypointParams(format='xy')\n",
    ")\n",
    "\n",
    "def get_train_image_only_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            #A.Resize(360,640),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "            ],p=0.9),\n",
    "            A.Blur(blur_limit=3,p=0.2),\n",
    "            A.Normalize(mean=mean,std=std,p=1.0,max_pixel_value=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        additional_targets={'image': 'image'}\n",
    "    )\n",
    "\n",
    "def get_valid_trainsforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            #A.Resize(360,640,interpolation=2),\n",
    "            A.Normalize(mean=mean,std=std,p=1.0,max_pixel_value=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# def get_valid_image_only_transforms():\n",
    "#     return A.Compose(\n",
    "#         [\n",
    "#             A.Resize(360,640),\n",
    "#         ],\n",
    "#         additional_targets={'image': 'image'}\n",
    "#     )\n",
    "\n",
    "#mean = torch.tensor([0.4939, 0.4794, 0.4583])\n",
    "#std = torch.tensor([0.2177, 0.2134, 0.2144])\n",
    "mean = torch.tensor([0.38868062, 0.38568735, 0.39457315])\n",
    "std = torch.tensor([0.221865, 0.23096273, 0.2210397])\n",
    "\n",
    "def denormalize(img):\n",
    "    img = img * std[...,None,None] + mean[...,None,None]\n",
    "    img = img.permute(1,2,0).cpu().numpy()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counting_Dataset(Dataset):\n",
    "    def __init__(self,path,image_fnames,dmap_folder,gt_folder=None,transforms=None,mosaic=False,downsample=4):\n",
    "        '''\n",
    "            path: root path \n",
    "            image_fnames: path of images\n",
    "            dmap_folder: density map folder, eg: /dmap\n",
    "            gt_folder: gt folder, currently set to visdrone xml format, modify _get_gt_data() if needed\n",
    "            transforms: iteratable, can be tuple / list ... etc\n",
    "            mosaic: mix up image and density map to form a new image, set to false by default\n",
    "            downsample: resize dmap\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.image_fnames = image_fnames\n",
    "        self.dmap_folder = path + dmap_folder\n",
    "        self.transforms = transforms\n",
    "        self.mosaic = mosaic\n",
    "        self.downsample = downsample\n",
    "        self.gt_folder = gt_folder # test purpose\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_fnames[idx]\n",
    "        \n",
    "        if self.mosaic and random.randint(0,1) < 0.5:\n",
    "            image, density_map, gt_points = self._load_mosaic_image_and_density_map(idx)\n",
    "        else:\n",
    "            image, density_map, gt_points = self._load_image_and_density_map(idx)\n",
    "        \n",
    "        h,w = image.shape[0]//self.downsample, image.shape[1]//self.downsample\n",
    "        image = cv2.resize(image,(w, h))\n",
    "        density_map = cv2.resize(density_map,(w//(self.downsample*2),h//(self.downsample*2)))#,interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Warning: doesn't work for cutout, uncommet transform and make fix code to enable cutout\n",
    "        # Reason: cutout doesn't apply to mask, so mask must be image. check 01a bottom for code\n",
    "        if self.transforms:\n",
    "            for tfms in self.transforms:\n",
    "                aug = tfms(**{\n",
    "                    'image': image,\n",
    "                    'mask': density_map,\n",
    "                    #'keypoints': gt_points\n",
    "                })\n",
    "                #image, density_map, gt_points = aug['image'], aug['mask'], aug['keypoints']\n",
    "                image, density_map = aug['image'], aug['mask'] # issue with previous keypoints (albumentation?)\n",
    "        \n",
    "        \n",
    "        return image, density_map, image_id, gt_points\n",
    "        \n",
    "    \n",
    "    def _get_dmap_name(self,fn):\n",
    "        mask_name = fn.split('/')[-1].split('.')[0]\n",
    "        mask_path = self.dmap_folder + '/' + mask_name + '.npy'\n",
    "        return mask_path\n",
    "    \n",
    "    def _load_image_and_density_map(self,idx):\n",
    "        image_fname = self.image_fnames[idx]\n",
    "        dmap_fname = self._get_dmap_name(image_fname)\n",
    "        image = cv2.imread(image_fname)\n",
    "        d_map = np.load(dmap_fname,allow_pickle=True)\n",
    "        d_map = d_map.squeeze()\n",
    "        if image.shape[0] < 384:\n",
    "            padding = (384 - image.shape[0]) // 2\n",
    "            image = cv2.copyMakeBorder(image, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "            d_map = cv2.copyMakeBorder(d_map, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = image/255.\n",
    "        \n",
    "        #sanity check gt\n",
    "        _, points = self._get_gt_data(idx)\n",
    "        # end sanity check\n",
    "        \n",
    "        return image, d_map, points\n",
    "    \n",
    "    def _load_mosaic_image_and_density_map(self,idx):\n",
    "        image_1, dmap_1, points_1 = self._load_image_and_density_map(idx)\n",
    "        while True:\n",
    "            idx_2 = random.randint(0,len(self.image_fnames)-1)\n",
    "            if idx != idx_2:\n",
    "                break\n",
    "        image_2, dmap_2, points_2 = self._load_image_and_density_map(idx_2)\n",
    "        \n",
    "        imsize = min(*image_1.shape[:2])\n",
    "        xc,yc = [int(random.uniform(imsize*0.4,imsize*0.6)) for _ in range(2)]\n",
    "        h,w = image_1.shape[0], image_1.shape[1]\n",
    "\n",
    "        pos = random.randint(0,1)\n",
    "        if pos == 0: #top left\n",
    "            x1a,y1a,x2a,y2a = 0,0,xc,yc # img_1\n",
    "            x1b,y1b,x2b,y2b = w-xc,h-yc,w,h # img_2\n",
    "        elif pos == 1: # top right\n",
    "            x1a,y1a,x2a,y2a = w-xc,0,w,yc\n",
    "            x1b,y1b,x2b,y2b = 0,h-yc,xc,h\n",
    "        elif pos == 2: # bottom left\n",
    "            x1a,y1a,x2a,y2a = 0,h-yc,xc,h\n",
    "            x1b,y1b,x2b,y2b = w-xc,0,w,yc\n",
    "        elif pos == 3: # bottom right\n",
    "            x1a,y1a,x2a,y2a = w-xc,h-yc,w,h\n",
    "            x1b,y1b,x2b,y2b = 0,0,xc,yc\n",
    "        \n",
    "        new_image = image_1.copy()\n",
    "        new_dmap = dmap_1.copy()\n",
    "        new_image[y1a:y2a,x1a:x2a] = image_2[y1b:y2b,x1b:x2b]\n",
    "        new_dmap[y1a:y2a,x1a:x2a] = dmap_2[y1b:y2b,x1b:x2b]\n",
    "        \n",
    "        #TODO: sanity check to see generate gt\n",
    "        \n",
    "        new_gt_points = self._get_mixed_gt_points(points_1,points_2,(x1a,y1a,x2a,y2a),(x1b,y1b,x2b,y2b),(h,w))\n",
    "        \n",
    "        return new_image, new_dmap, new_gt_points\n",
    "    \n",
    "    '''\n",
    "    The follow section blocks are for sanity check \n",
    "    to compare dmap.sum() with gt points\n",
    "    remove if needed\n",
    "    '''\n",
    "    def _get_mixed_gt_points(self,points_1,points_2,img_1_loc, img_2_loc,img_shape):\n",
    "#         fn_1, points_1 = self._get_gt_data(idx_1)\n",
    "#         fn_2, points_2 = self._get_gt_data(idx_2)\n",
    "        x1a,y1a,x2a,y2a = img_1_loc\n",
    "        x1b,y1b,x2b,y2b = img_2_loc\n",
    "        h,w = img_shape\n",
    "        \n",
    "        result_boxes = []\n",
    "        result_boxes.append(points_2)\n",
    "        result_boxes = np.concatenate(result_boxes,0)\n",
    "        padw = x1a-x1b\n",
    "        pady = y1a-y1b\n",
    "\n",
    "        result_boxes[:,0] += padw\n",
    "        result_boxes[:,1] += pady\n",
    "\n",
    "        np.clip(result_boxes[:,0],0,w,out=result_boxes[:,0])\n",
    "        np.clip(result_boxes[:,1],0,h,out=result_boxes[:,1])\n",
    "        result_boxes = result_boxes.astype(np.int32)\n",
    "\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,0] * result_boxes[:,1] > 0)]\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,0] < w)]\n",
    "        result_boxes = result_boxes[np.where(result_boxes[:,1] < h)]\n",
    "        \n",
    "        boxes = []\n",
    "        for (x,y) in points_1:\n",
    "            if x >= x1a and x <= x2a and y >= y1a and y <= y2a:\n",
    "                continue\n",
    "            else:\n",
    "                boxes.append((x,y))\n",
    "        if len(boxes) == 0:\n",
    "            return result_boxes\n",
    "        return np.concatenate((boxes, result_boxes),axis=0)\n",
    "    \n",
    "    def _get_gt_data(self,idx):\n",
    "        if not self.gt_folder:\n",
    "            return (None,0)\n",
    "        fn = self.image_fnames[idx]\n",
    "        anno_path = self.path + self.gt_folder + '/' + fn.split('/')[-1].split('.')[0] + '.mat'\n",
    "        test_data = loadmat(anno_path)\n",
    "        points = test_data['annotation'].astype(int)\n",
    "        return fn, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD LOG_PARA to density map\n",
    "\n",
    "class Crop_Dataset(Counting_Dataset):\n",
    "    def __init__(self,path,image_fnames,dmap_folder,gt_folder=None,transforms=None,mosaic=False,downsample=4,crop_size=512,method='train'):\n",
    "        super().__init__(path,image_fnames,dmap_folder,gt_folder,transforms,mosaic,downsample)\n",
    "        self.crop_size = crop_size\n",
    "        if method not in ['train','valid']:\n",
    "            raise Exception('Not Implement')\n",
    "        self.method = method\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        fn = self.image_fnames[idx]\n",
    "        \n",
    "        image,density_map,gt_points = self._load_image_and_density_map(idx)\n",
    "        density_map = density_map.squeeze()\n",
    "        h,w = image.shape[0], image.shape[1]\n",
    "        #image = cv2.resize(image,(w, h))\n",
    "        \n",
    "        if self.method == 'train':\n",
    "            #h,w = image.shape[:2]\n",
    "            i,j = self._random_crop(h,w,self.crop_size,self.crop_size)\n",
    "            image = image[i:i+self.crop_size,j:j+self.crop_size]\n",
    "            density_map = density_map[i:i+self.crop_size,j:j+self.crop_size]\n",
    "            #print(density_map.shape)\n",
    "            #gt_points = gt_points - [j,i]\n",
    "            #mask = (gt_points[:,0] >=0 ) * (gt_points[:,0] <= self.crop_size) * (gt_points[:,1]>=0) * (gt_points[:,1]<=self.crop_size)\n",
    "            #gt_points = gt_points[mask]\n",
    "            density_map = cv2.resize(density_map,(self.crop_size//self.downsample,self.crop_size//self.downsample))\n",
    "            \n",
    "        else:\n",
    "            density_map = cv2.resize(density_map,(w//self.downsample,h//self.downsample))#,interpolation=cv2.INTER_NEAREST)\n",
    "            #density_map = density_map[1:-1,:]\n",
    "        \n",
    "        if self.transforms:\n",
    "            for tfms in self.transforms:\n",
    "                aug = tfms(**{\n",
    "                    'image': image,\n",
    "                    'mask': density_map,\n",
    "                    #'keypoints': gt_points\n",
    "                })\n",
    "                #image, density_map, gt_points = aug['image'], aug['mask'], aug['keypoints']\n",
    "                image, density_map = aug['image'], aug['mask'] # issue with previous keypoints (albumentation?)\n",
    "        return image, density_map*LOG_PARA, fn, gt_points\n",
    "    \n",
    "    def _random_crop(self, im_h, im_w, crop_h, crop_w):\n",
    "        res_h = im_h - crop_h\n",
    "        res_w = im_w - crop_w\n",
    "        i = random.randint(0, res_h)\n",
    "        j = random.randint(0, res_w)\n",
    "        return i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = glob(images + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(fp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.76859727, 107.66019032, 106.60444393])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.mean(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3018/3018 [02:49<00:00, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 98.35027458 100.6161537   99.11355744]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "global_mean = AverageMeter()\n",
    "for fn in tqdm(fp):\n",
    "    img = cv2.imread(fn)\n",
    "    global_mean.update(img.mean(axis=(0,1)), img.shape[0]*img.shape[1])\n",
    "print(global_mean.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38568735, 0.39457315, 0.38868062])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_mean = global_mean.avg / 255.0\n",
    "g_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3018/3018 [01:07<00:00, 44.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23096273 0.2210397  0.221865  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "global_std2 = AverageMeter()\n",
    "for fn in tqdm(fp):\n",
    "    img = (cv2.imread(fn) - global_mean.avg) / 255.0\n",
    "    global_std2.update(np.mean(np.square(img), axis=(0,1)), img.shape[0]*img.shape[1])\n",
    "print(np.sqrt(global_std2.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3018/3018 [01:28<00:00, 34.15it/s]\n"
     ]
    }
   ],
   "source": [
    "new_fp = []\n",
    "for fn in tqdm(fp):\n",
    "    img = cv2.imread(fn)\n",
    "    h, w, _ = img.shape\n",
    "    if h == 512 and w == 688:\n",
    "        new_fp.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999990_00000_d_0000045.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999955_00000_d_0000100.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999994_00000_d_0000069.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999955_00000_d_0000311.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999955_00000_d_0000165.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999998_00072_d_0000057.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999998_00398_d_0000350.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999998_00278_d_0000231.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/9999998_00105_d_0000083.jpg',\n",
       " '/mnt/home/zpengac/USERDIR/count/drone_dataset/rf_image_vehicle/0000264_04401_d_0000216.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(len(fp) * 0.8)\n",
    "fp[0:split][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3018/3018 [02:11<00:00, 22.89it/s]\n"
     ]
    }
   ],
   "source": [
    "hs = []\n",
    "ws = []\n",
    "for fn in tqdm(fp):\n",
    "    img = cv2.imread(fn)\n",
    "    h, w, _ = img.shape\n",
    "    hs.append(h)\n",
    "    ws.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = np.array(hs)\n",
    "ws = np.array(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([368, 384, 512, 528, 736]), array([ 561,  418, 1124,  505,  410]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_counts = np.unique(hs, return_counts=True)\n",
    "h_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([672, 688, 944, 960, 992]), array([ 561, 1542,  160,  345,  410]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_counts = np.unique(ws, return_counts=True)\n",
    "w_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hws = list(zip(hs, ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 688)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[368, 672],\n",
       "        [384, 688],\n",
       "        [512, 688],\n",
       "        [528, 944],\n",
       "        [528, 960],\n",
       "        [736, 992]]),\n",
       " array([ 561,  418, 1124,  160,  345,  410]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_counts = np.unique(hws, return_counts=True, axis=0)\n",
    "hw_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfp = glob(path + '/rf_image_vehicle' + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4939/4939 [03:07<00:00, 26.37it/s]\n"
     ]
    }
   ],
   "source": [
    "hws = []\n",
    "for fn in tqdm(vfp):\n",
    "    img = cv2.imread(fn)\n",
    "    h, w, _ = img.shape\n",
    "    hws.append((h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[352, 480],\n",
       "        [368, 672],\n",
       "        [384, 688],\n",
       "        [512, 688],\n",
       "        [528, 944],\n",
       "        [528, 960],\n",
       "        [736, 992]]),\n",
       " array([   1,  662,  928, 1921,  353,  415,  659]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_counts = np.unique(hws, return_counts=True, axis=0)\n",
    "hw_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hws = np.array([[352, 480],\n",
    "        [368, 672],\n",
    "        [384, 688],\n",
    "        [512, 688],\n",
    "        [528, 944],\n",
    "        [528, 960],\n",
    "        [736, 992]])\n",
    "cts = np.array([1, 662, 928, 1921, 353, 415, 659])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    352,     480],\n",
       "       [ 243616,  444864],\n",
       "       [ 356352,  638464],\n",
       "       [ 983552, 1321648],\n",
       "       [ 186384,  333232],\n",
       "       [ 219120,  398400],\n",
       "       [ 485024,  653728]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hws[:,0] *= cts\n",
    "hws[:,1] *= cts\n",
    "hws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([503.02907095, 770.64769262])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hws.sum(axis=0)/4919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Crop_Dataset(path=path,\n",
    "                             image_fnames=fp[:split],dmap_folder='/rf_GT_vehicle',\n",
    "                             #gt_folder='/annotation',\n",
    "                             transforms=[get_train_transforms(),get_train_image_only_transforms()],\n",
    "                             downsample=1,\n",
    "                             crop_size=384\n",
    "                                )\n",
    "\n",
    "valid_dataset = Crop_Dataset(path=path,\n",
    "                             image_fnames=fp[split:],dmap_folder='/rf_GT_vehicle',\n",
    "                             #gt_folder='/annotation',\n",
    "                             transforms=[get_valid_trainsforms()],\n",
    "                             method='valid',\n",
    "                             downsample=1\n",
    "                             #crop_size=448\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, dmap, fn, pt = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 32\n",
    "    batch_size = 16\n",
    "    n_epochs = 60 \n",
    "    lr = 0.0002\n",
    "\n",
    "    folder = 'test_delete'\n",
    "    downsample = 1\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = True  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = False  # do scheduler.step after validation stage loss\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "    scheduler_params = dict(\n",
    "        max_lr=1e-4,\n",
    "        #total_steps = len(train_dataset) // 4 * n_epochs, # gradient accumulation\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "        pct_start=0.2,\n",
    "        anneal_strategy='cos', \n",
    "        final_div_factor=10**5\n",
    "    )\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "#     scheduler_params = dict(\n",
    "#         mode='min',\n",
    "#         factor=0.5,\n",
    "#         patience=1,\n",
    "#         verbose=False, \n",
    "#         threshold=0.0001,\n",
    "#         threshold_mode='abs',\n",
    "#         cooldown=0, \n",
    "#         min_lr=1e-8,\n",
    "#         eps=1e-08\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
    "        super(SeparableConv2d,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        if out_filters != in_filters or strides!=1:\n",
    "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
    "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
    "        else:\n",
    "            self.skip=None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep=[]\n",
    "\n",
    "        filters=in_filters\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "            filters = out_filters\n",
    "\n",
    "        for i in range(reps-1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "        else:\n",
    "            rep[0] = nn.ReLU(inplace=False)\n",
    "\n",
    "        if strides != 1:\n",
    "            rep.append(nn.MaxPool2d(3,strides,1))\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self,inp):\n",
    "        x = self.rep(inp)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "\n",
    "        x+=skip\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    \"\"\"\n",
    "    Xception optimized for the ImageNet dataset, as specified in\n",
    "    https://arxiv.org/pdf/1610.02357.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=1000):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            num_classes: number of classes\n",
    "        \"\"\"\n",
    "        super(Xception, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        #do relu here\n",
    "\n",
    "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
    "        self.block2=Block(128,256,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block3=Block(256,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        #self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        #self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        #self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        #self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        #self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block11=Block(728,728,2,2,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block12=Block(728,512,3,1,start_with_relu=True,grow_first=False)\n",
    "\n",
    "        self.conv3 = SeparableConv2d(512,512,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(512)\n",
    "\n",
    "        #do relu here\n",
    "        self.conv4 = SeparableConv2d(512,512,3,1,1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "        #self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        # #------- init weights --------\n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Conv2d):\n",
    "        #         n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        #         m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        #     elif isinstance(m, nn.BatchNorm2d):\n",
    "        #         m.weight.data.fill_(1)\n",
    "        #         m.bias.data.zero_()\n",
    "        # #-----------------------------\n",
    "\n",
    "    def features(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        # x = self.block4(x)\n",
    "        # x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        # x = self.block8(x)\n",
    "        # x = self.block9(x)\n",
    "        # x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        # x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SANet, self).__init__()\n",
    "        self.FME=Xception()\n",
    "        self.DME = nn.Sequential(nn.Conv2d(512, 64, 9, 1, padding=4),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.Conv2d(64, 32, 7, 1, padding=3),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.Conv2d(32, 16, 5, 1, padding=2),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.Conv2d(16, 16, 3, 1, padding=1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               nn.Conv2d(16, 16, 5, 1, padding=2),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                               # nn.Conv2d(16, 16, 3, 1, padding=2, dilation=2),\n",
    "                               nn.Conv2d(16, 1, 1, 1, padding=0))    \n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, x):\n",
    "        # x = self.layer1(x)\n",
    "        # x = self.layer2(x)\n",
    "        x = self.FME(x)\n",
    "        x = self.DME(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SANet()\n",
    "x = torch.rand(2,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = m.FME(x)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 224, 224])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = m.DME(x1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss_MCNN(preds,targs):\n",
    "    return nn.MSELoss()(preds,targs)\n",
    "\n",
    "def MAELoss_MCNN(preds,targs,upsample):\n",
    "    return nn.L1Loss()((preds/LOG_PARA).sum(dim=[-1,-2])*upsample*upsample, (targs/LOG_PARA).sum(dim=[-1,-2])*upsample*upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#opt_level ='O1' # apex\n",
    "\n",
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10**5\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        \n",
    "        #self.model, self.optimizer = amp.initialize(self.model,self.optimizer,opt_level=opt_level) # apex\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.criterion = MSELoss_MCNN\n",
    "        self.metric = MAELoss_MCNN\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "        \n",
    "        # self.iters_to_accumulate = 4 # gradient accumulation\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, mae_loss = self.train_one_epoch(train_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, mae_loss: {mae_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, mae_loss = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, mse_loss: {summary_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, mae_loss: {mae_loss.avg:.8f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        mae_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, density_maps, fns, gt_pts) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'mse_loss: {summary_loss.avg:.8f}, ' + \\\n",
    "                        f'mae_loss: {mae_loss.avg:.8f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.cuda().float()\n",
    "                density_maps = density_maps.cuda().float()\n",
    "                \n",
    "\n",
    "                #preds = self.model(images)\n",
    "                with torch.cuda.amp.autocast(): #native fp16\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds,density_maps)\n",
    "                    metric_loss = self.metric(preds,density_maps,self.config.downsample)\n",
    "                mae_loss.update(metric_loss.detach().item(),batch_size)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "                \n",
    "            #if step == 20:\n",
    "            #    break\n",
    "\n",
    "        return summary_loss, mae_loss\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        mae_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, density_maps, fns, gt_pts) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'mse_loss: {summary_loss.avg:.8f}, ' + \\\n",
    "                        f'mae_loss: {mae_loss.avg:.8f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            \n",
    "            images = images.cuda().float()\n",
    "            batch_size = images.shape[0]\n",
    "            density_maps = density_maps.cuda().float()\n",
    "            \n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast(): #native fp16\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds,density_maps)\n",
    "                metric_loss = self.metric(preds.detach(),density_maps.detach(),self.config.downsample)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            # loss = loss / self.iters_to_accumulate # gradient accumulation\n",
    "            \n",
    "#             with amp.scale_loss(loss,self.optimizer) as scaled_loss: # apex\n",
    "#                 scaled_loss.backward()\n",
    "            #loss.backward()\n",
    "\n",
    "            \n",
    "            mae_loss.update(metric_loss.detach().item(),batch_size)\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "            \n",
    "            #self.optimizer.step()\n",
    "            self.scaler.step(self.optimizer) # native fp16\n",
    "            \n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            self.scaler.update() #native fp16\n",
    "                \n",
    "                \n",
    "#             if (step+1) % self.iters_to_accumulate == 0: # gradient accumulation\n",
    "\n",
    "#                 self.optimizer.step()\n",
    "#                 self.optimizer.zero_grad()\n",
    "\n",
    "#                 if self.config.step_scheduler:\n",
    "#                     self.scheduler.step()\n",
    "                    \n",
    "            #if step == 20:\n",
    "            #    break\n",
    "\n",
    "        return summary_loss, mae_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_summary_loss': self.best_summary_loss,\n",
    "            'epoch': self.epoch,\n",
    "            #'amp': amp.state_dict() # apex\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
    "        self.epoch = checkpoint['epoch'] + 1\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs, dmaps, fns, gt_points = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    dmaps = torch.stack(dmaps).unsqueeze(1)\n",
    "    return imgs,dmaps,fns,gt_points\n",
    "\n",
    "def run_training():\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=RandomSampler(train_dataset),\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=1, #TrainGlobalConfig.batch_size,\n",
    "        num_workers=1, #TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(valid_dataset),\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "#     fitter.load(f'{fitter.base_dir}/last-checkpoint.bin')\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SANet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2021-08-18T02:42:06.746759\n",
      "LR: 4.000000000000002e-06\n",
      "[RESULT]: Train. Epoch: 0, mse_loss: 4.00714399, time: 203.93485 time: 203.45986\n",
      "[RESULT]: Train. Epoch: 0, mae_loss: 10.88933182, time: 203.94619\n",
      "[RESULT]: Val. Epoch: 0, mse_loss: 3.12142004, time: 37.42814, time: 37.22913\n",
      "[RESULT]: Val. Epoch: 0, mae_loss: 23.75919030, time: 37.44057\n",
      "\n",
      "2021-08-18T02:46:09.833063\n",
      "LR: 5.637368731251736e-06\n",
      "[RESULT]: Train. Epoch: 1, mse_loss: 4.01978595, time: 42.04533, time: 41.55518\n",
      "[RESULT]: Train. Epoch: 1, mae_loss: 10.41006905, time: 42.05597\n",
      "[RESULT]: Val. Epoch: 1, mse_loss: 3.11840532, time: 35.54313, time: 35.34507\n",
      "[RESULT]: Val. Epoch: 1, mae_loss: 19.78002225, time: 35.56962\n",
      "\n",
      "2021-08-18T02:47:29.311316\n",
      "LR: 1.0437767576586908e-05\n",
      "[RESULT]: Train. Epoch: 2, mse_loss: 3.97096324, time: 42.72437, time: 42.22923\n",
      "[RESULT]: Train. Epoch: 2, mae_loss: 10.79236276, time: 42.77752\n",
      "[RESULT]: Val. Epoch: 2, mse_loss: 3.11347011, time: 27.02315, time: 26.82492\n",
      "[RESULT]: Val. Epoch: 2, mae_loss: 36.94477825, time: 27.03010\n",
      "\n",
      "2021-08-18T02:48:41.136152\n",
      "LR: 1.8073695579051824e-05\n",
      "[RESULT]: Train. Epoch: 3, mse_loss: 3.94608694, time: 43.19492, time: 42.70389\n",
      "[RESULT]: Train. Epoch: 3, mae_loss: 11.29884346, time: 43.20405\n",
      "[RESULT]: Val. Epoch: 3, mse_loss: 3.11569970, time: 25.91834, time: 25.71571\n",
      "[RESULT]: Val. Epoch: 3, mae_loss: 45.22262925, time: 25.92576\n",
      "\n",
      "2021-08-18T02:49:51.002635\n",
      "LR: 2.80242014992579e-05\n",
      "[RESULT]: Train. Epoch: 4, mse_loss: 4.01501263, time: 41.68344, time: 41.16905\n",
      "[RESULT]: Train. Epoch: 4, mae_loss: 11.46291502, time: 41.69376\n",
      "[RESULT]: Val. Epoch: 4, mse_loss: 3.06364162, time: 26.52106, time: 26.28352\n",
      "[RESULT]: Val. Epoch: 4, mae_loss: 20.84774452, time: 26.52791\n",
      "\n",
      "2021-08-18T02:51:00.795524\n",
      "LR: 3.961042503496012e-05\n",
      "[RESULT]: Train. Epoch: 5, mse_loss: 3.88608172, time: 43.32805, time: 42.84342\n",
      "[RESULT]: Train. Epoch: 5, mae_loss: 10.78000009, time: 43.33709\n",
      "[RESULT]: Val. Epoch: 5, mse_loss: 3.05786967, time: 24.16494, time: 23.96745\n",
      "[RESULT]: Val. Epoch: 5, mae_loss: 17.98959268, time: 24.17595\n",
      "\n",
      "2021-08-18T02:52:10.541537\n",
      "LR: 5.204191118071466e-05\n",
      "[RESULT]: Train. Epoch: 6, mse_loss: 3.93386710, time: 43.95410, time: 43.42547\n",
      "[RESULT]: Train. Epoch: 6, mae_loss: 11.01866354, time: 44.00846\n",
      "[RESULT]: Val. Epoch: 6, mse_loss: 3.05236267, time: 32.12978, time: 31.92522\n",
      "[RESULT]: Val. Epoch: 6, mae_loss: 17.37889476, time: 32.15108\n",
      "\n",
      "2021-08-18T02:53:29.149990\n",
      "LR: 6.447053799076954e-05\n",
      "[RESULT]: Train. Epoch: 7, mse_loss: 3.87750035, time: 43.19936, time: 42.68735\n",
      "[RESULT]: Train. Epoch: 7, mae_loss: 10.59737463, time: 43.24369\n",
      "[RESULT]: Val. Epoch: 7, mse_loss: 3.03165364, time: 37.29137, time: 37.06334\n",
      "[RESULT]: Val. Epoch: 7, mae_loss: 16.29727030, time: 37.31331\n",
      "\n",
      "2021-08-18T02:54:53.726447\n",
      "LR: 7.604837859382552e-05\n",
      "[RESULT]: Train. Epoch: 8, mse_loss: 3.78072767, time: 42.56922, time: 42.08379\n",
      "[RESULT]: Train. Epoch: 8, mae_loss: 10.59103607, time: 42.58312\n",
      "[RESULT]: Val. Epoch: 8, mse_loss: 3.08047224, time: 27.75151, time: 27.53795\n",
      "[RESULT]: Val. Epoch: 8, mae_loss: 38.34558660, time: 27.75673\n",
      "\n",
      "2021-08-18T02:56:04.823040\n",
      "LR: 8.598554989909681e-05\n",
      "[RESULT]: Train. Epoch: 9, mse_loss: 3.86351212, time: 41.71444, time: 41.22407\n",
      "[RESULT]: Train. Epoch: 9, mae_loss: 10.30075741, time: 42.21910\n",
      "[RESULT]: Val. Epoch: 9, mse_loss: 2.96475130, time: 25.31885, time: 25.12075\n",
      "[RESULT]: Val. Epoch: 9, mae_loss: 20.68552336, time: 25.32888\n",
      "\n",
      "2021-08-18T02:57:14.128335\n",
      "LR: 9.360410134106905e-05\n",
      "[RESULT]: Train. Epoch: 10, mse_loss: 3.77500065, time: 42.26706 time: 41.78207\n",
      "[RESULT]: Train. Epoch: 10, mae_loss: 10.23922555, time: 42.27909\n",
      "[RESULT]: Val. Epoch: 10, mse_loss: 3.00708921, time: 24.42813 time: 24.23041\n",
      "[RESULT]: Val. Epoch: 10, mae_loss: 21.55220949, time: 24.43493\n",
      "\n",
      "2021-08-18T02:58:21.638764\n",
      "LR: 9.838426717355399e-05\n",
      "[RESULT]: Train. Epoch: 11, mse_loss: 3.68420057, time: 44.10998time: 43.58548\n",
      "[RESULT]: Train. Epoch: 11, mae_loss: 9.85444344, time: 44.11981\n",
      "[RESULT]: Val. Epoch: 11, mse_loss: 2.90161487, time: 24.48102 time: 24.27892\n",
      "[RESULT]: Val. Epoch: 11, mae_loss: 17.54186872, time: 24.48710\n",
      "\n",
      "2021-08-18T02:59:32.149961\n",
      "LR: 9.99999952403548e-05\n",
      "[RESULT]: Train. Epoch: 12, mse_loss: 3.61459410, time: 44.75766time: 44.20776\n",
      "[RESULT]: Train. Epoch: 12, mae_loss: 9.68410987, time: 44.76900\n",
      "[RESULT]: Val. Epoch: 12, mse_loss: 2.97137991, time: 25.98201 time: 25.79156\n",
      "[RESULT]: Val. Epoch: 12, mae_loss: 14.99570834, time: 25.98870\n",
      "\n",
      "2021-08-18T03:00:43.691535\n",
      "LR: 9.989151458098059e-05\n",
      "[RESULT]: Train. Epoch: 13, mse_loss: 3.59044599, time: 43.16421time: 42.67713\n",
      "[RESULT]: Train. Epoch: 13, mae_loss: 9.57127584, time: 43.17422\n",
      "[RESULT]: Val. Epoch: 13, mse_loss: 2.84359667, time: 26.03450 time: 25.80579\n",
      "[RESULT]: Val. Epoch: 13, mae_loss: 28.26230447, time: 26.04140\n",
      "\n",
      "2021-08-18T03:01:54.386329\n",
      "LR: 9.956939088232902e-05\n",
      "[RESULT]: Train. Epoch: 14, mse_loss: 3.60591460, time: 42.03923time: 41.56277\n",
      "[RESULT]: Train. Epoch: 14, mae_loss: 9.16991216, time: 42.11038\n",
      "[RESULT]: Val. Epoch: 14, mse_loss: 2.87742618, time: 24.73569 time: 24.52853\n",
      "[RESULT]: Val. Epoch: 14, mae_loss: 28.47975242, time: 24.73983\n",
      "\n",
      "2021-08-18T03:03:02.283417\n",
      "LR: 9.903500352753105e-05\n",
      "[RESULT]: Train. Epoch: 15, mse_loss: 3.53337942, time: 42.06750time: 41.56357\n",
      "[RESULT]: Train. Epoch: 15, mae_loss: 9.18610669, time: 42.07454\n",
      "[RESULT]: Val. Epoch: 15, mse_loss: 2.90273572, time: 28.78219 time: 28.55326\n",
      "[RESULT]: Val. Epoch: 15, mae_loss: 19.22637949, time: 28.81022\n",
      "\n",
      "2021-08-18T03:04:14.061038\n",
      "LR: 9.829064084528058e-05\n",
      "[RESULT]: Train. Epoch: 16, mse_loss: 3.53537104, time: 42.11315time: 41.61150\n",
      "[RESULT]: Train. Epoch: 16, mae_loss: 8.96129252, time: 42.16653\n",
      "[RESULT]: Val. Epoch: 16, mse_loss: 2.71286665, time: 30.26556 time: 30.03196\n",
      "[RESULT]: Val. Epoch: 16, mae_loss: 16.17939546, time: 30.28630\n",
      "\n",
      "2021-08-18T03:05:28.697693\n",
      "LR: 9.733949031085962e-05\n",
      "[RESULT]: Train. Epoch: 17, mse_loss: 3.56489061, time: 42.30749time: 41.82155\n",
      "[RESULT]: Train. Epoch: 17, mae_loss: 8.97676592, time: 42.31773\n",
      "[RESULT]: Val. Epoch: 17, mse_loss: 3.21423165, time: 36.16672 time: 35.93397\n",
      "[RESULT]: Val. Epoch: 17, mae_loss: 78.49881578, time: 36.17539\n",
      "\n",
      "2021-08-18T03:06:48.183928\n",
      "LR: 9.618562489687986e-05\n",
      "[RESULT]: Train. Epoch: 18, mse_loss: 3.48020511, time: 44.44702time: 43.94506\n",
      "[RESULT]: Train. Epoch: 18, mae_loss: 8.92358419, time: 44.47329\n",
      "[RESULT]: Val. Epoch: 18, mse_loss: 2.74112372, time: 25.03949 time: 24.83759\n",
      "[RESULT]: Val. Epoch: 18, mae_loss: 28.57775461, time: 25.04541\n",
      "\n",
      "2021-08-18T03:07:58.668073\n",
      "LR: 9.483398563218861e-05\n",
      "[RESULT]: Train. Epoch: 19, mse_loss: 3.44180147, time: 43.74885time: 43.18062\n",
      "[RESULT]: Train. Epoch: 19, mae_loss: 8.65068971, time: 43.75968\n",
      "[RESULT]: Val. Epoch: 19, mse_loss: 2.74664280, time: 26.42156 time: 26.19535\n",
      "[RESULT]: Val. Epoch: 19, mae_loss: 22.51200383, time: 26.45967\n",
      "\n",
      "2021-08-18T03:09:09.668791\n",
      "LR: 9.329036044362469e-05\n",
      "[RESULT]: Train. Epoch: 20, mse_loss: 3.39508576, time: 43.07654time: 42.59592\n",
      "[RESULT]: Train. Epoch: 20, mae_loss: 8.29303899, time: 43.12881\n",
      "[RESULT]: Val. Epoch: 20, mse_loss: 3.05547456, time: 32.75517 time: 32.53059\n",
      "[RESULT]: Val. Epoch: 20, mae_loss: 62.35882604, time: 32.76631\n",
      "\n",
      "2021-08-18T03:10:26.542215\n",
      "LR: 9.156135937122721e-05\n",
      "[RESULT]: Train. Epoch: 21, mse_loss: 3.43293389, time: 42.86870time: 42.36611\n",
      "[RESULT]: Train. Epoch: 21, mae_loss: 8.41566991, time: 42.87635\n",
      "[RESULT]: Val. Epoch: 21, mse_loss: 2.66656111, time: 33.20133 time: 32.99709\n",
      "[RESULT]: Val. Epoch: 21, mae_loss: 12.30963503, time: 33.25374\n",
      "\n",
      "2021-08-18T03:11:44.830721\n",
      "LR: 8.965438626302922e-05\n",
      "[RESULT]: Train. Epoch: 22, mse_loss: 3.34051197, time: 43.45840time: 42.89505\n",
      "[RESULT]: Train. Epoch: 22, mae_loss: 7.94385172, time: 43.46732\n",
      "[RESULT]: Val. Epoch: 22, mse_loss: 2.63595294, time: 25.52855 time: 25.32238\n",
      "[RESULT]: Val. Epoch: 22, mae_loss: 17.03278161, time: 25.61489\n",
      "\n",
      "2021-08-18T03:12:55.414626\n",
      "LR: 8.757760707064388e-05\n",
      "[RESULT]: Train. Epoch: 23, mse_loss: 3.33280424, time: 42.81712time: 42.30821\n",
      "[RESULT]: Train. Epoch: 23, mae_loss: 8.28075914, time: 42.87247\n",
      "[RESULT]: Val. Epoch: 23, mse_loss: 2.64800167, time: 39.64352 time: 39.48475\n",
      "[RESULT]: Val. Epoch: 23, mae_loss: 16.96787797, time: 39.64993\n",
      "\n",
      "2021-08-18T03:14:19.097123\n",
      "LR: 8.533991488140592e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 24, mse_loss: 3.31446043, time: 43.40215time: 42.90468\n",
      "[RESULT]: Train. Epoch: 24, mae_loss: 7.96157673, time: 43.45733\n",
      "[RESULT]: Val. Epoch: 24, mse_loss: 2.60808720, time: 32.73385 time: 32.53639\n",
      "[RESULT]: Val. Epoch: 24, mae_loss: 12.01242156, time: 32.74513\n",
      "\n",
      "2021-08-18T03:15:36.943797\n",
      "LR: 8.295089183680643e-05\n",
      "[RESULT]: Train. Epoch: 25, mse_loss: 3.33273862, time: 43.36100time: 42.86896\n",
      "[RESULT]: Train. Epoch: 25, mae_loss: 7.92694974, time: 43.38705\n",
      "[RESULT]: Val. Epoch: 25, mse_loss: 2.58129422, time: 26.23310 time: 26.03336\n",
      "[RESULT]: Val. Epoch: 25, mae_loss: 14.56291032, time: 26.23973\n",
      "\n",
      "2021-08-18T03:16:49.766804\n",
      "LR: 8.042076810029185e-05\n",
      "[RESULT]: Train. Epoch: 26, mse_loss: 3.31530960, time: 42.13334time: 41.55435\n",
      "[RESULT]: Train. Epoch: 26, mae_loss: 7.29687728, time: 42.18799\n",
      "[RESULT]: Val. Epoch: 26, mse_loss: 2.88435054, time: 25.55681 time: 25.32942\n",
      "[RESULT]: Val. Epoch: 26, mae_loss: 38.47588582, time: 25.56211\n",
      "\n",
      "2021-08-18T03:17:58.537910\n",
      "LR: 7.77603780501336e-05\n",
      "[RESULT]: Train. Epoch: 27, mse_loss: 3.27077752, time: 44.82247time: 44.33026\n",
      "[RESULT]: Train. Epoch: 27, mae_loss: 7.70901169, time: 44.83404\n",
      "[RESULT]: Val. Epoch: 27, mse_loss: 2.61795471, time: 26.61409 time: 26.41022\n",
      "[RESULT]: Val. Epoch: 27, mae_loss: 11.03075097, time: 26.64185\n",
      "\n",
      "2021-08-18T03:19:10.743722\n",
      "LR: 7.498111388495697e-05\n",
      "[RESULT]: Train. Epoch: 28, mse_loss: 3.30242314, time: 43.55746time: 43.06322\n",
      "[RESULT]: Train. Epoch: 28, mae_loss: 7.81222184, time: 43.56789\n",
      "[RESULT]: Val. Epoch: 28, mse_loss: 2.56969632, time: 27.67363 time: 27.51859\n",
      "[RESULT]: Val. Epoch: 28, mae_loss: 17.00827854, time: 27.68043\n",
      "\n",
      "2021-08-18T03:20:23.474909\n",
      "LR: 7.209487684059767e-05\n",
      "[RESULT]: Train. Epoch: 29, mse_loss: 3.29590045, time: 42.32468time: 41.79813\n",
      "[RESULT]: Train. Epoch: 29, mae_loss: 7.35224478, time: 42.33432\n",
      "[RESULT]: Val. Epoch: 29, mse_loss: 2.55283715, time: 31.33452 time: 31.10514\n",
      "[RESULT]: Val. Epoch: 29, mae_loss: 11.94662776, time: 31.34148\n",
      "\n",
      "2021-08-18T03:21:38.635027\n",
      "LR: 6.911402622718278e-05\n",
      "[RESULT]: Train. Epoch: 30, mse_loss: 3.22677700, time: 42.80606time: 42.29193\n",
      "[RESULT]: Train. Epoch: 30, mae_loss: 7.86709622, time: 42.85053\n",
      "[RESULT]: Val. Epoch: 30, mse_loss: 2.57185571, time: 37.23715 time: 37.04038\n",
      "[RESULT]: Val. Epoch: 30, mae_loss: 14.36795833, time: 37.24327\n",
      "\n",
      "2021-08-18T03:22:59.864817\n",
      "LR: 6.605132650466747e-05\n",
      "[RESULT]: Train. Epoch: 31, mse_loss: 3.13989226, time: 43.48902time: 42.98448\n",
      "[RESULT]: Train. Epoch: 31, mae_loss: 6.96572143, time: 43.51858\n",
      "[RESULT]: Val. Epoch: 31, mse_loss: 2.67242106, time: 32.25289 time: 32.04797\n",
      "[RESULT]: Val. Epoch: 31, mae_loss: 12.30784966, time: 32.28641\n",
      "\n",
      "2021-08-18T03:24:16.977484\n",
      "LR: 6.29198926234578e-05\n",
      "[RESULT]: Train. Epoch: 32, mse_loss: 3.16434827, time: 46.36152time: 45.82348\n",
      "[RESULT]: Train. Epoch: 32, mae_loss: 6.97063561, time: 46.37078\n",
      "[RESULT]: Val. Epoch: 32, mse_loss: 2.52961622, time: 25.36901 time: 25.11615\n",
      "[RESULT]: Val. Epoch: 32, mae_loss: 11.44827471, time: 25.39684\n",
      "\n",
      "2021-08-18T03:25:30.403068\n",
      "LR: 5.9733133864179526e-05\n",
      "[RESULT]: Train. Epoch: 33, mse_loss: 3.14200205, time: 42.78562time: 42.28529\n",
      "[RESULT]: Train. Epoch: 33, mae_loss: 6.67518845, time: 42.80511\n",
      "[RESULT]: Val. Epoch: 33, mse_loss: 2.54072901, time: 25.95086 time: 25.75628\n",
      "[RESULT]: Val. Epoch: 33, mae_loss: 11.12877172, time: 25.97875\n",
      "\n",
      "2021-08-18T03:26:40.088465\n",
      "LR: 5.650469641708e-05\n",
      "[RESULT]: Train. Epoch: 34, mse_loss: 3.09620801, time: 43.71360time: 43.21803\n",
      "[RESULT]: Train. Epoch: 34, mae_loss: 6.74601852, time: 43.77281\n",
      "[RESULT]: Val. Epoch: 34, mse_loss: 2.55682049, time: 25.50215 time: 25.27161\n",
      "[RESULT]: Val. Epoch: 34, mae_loss: 12.40990840, time: 25.51190\n",
      "\n",
      "2021-08-18T03:27:50.472172\n",
      "LR: 5.3248404946946475e-05\n",
      "[RESULT]: Train. Epoch: 35, mse_loss: 3.13286905, time: 42.52872time: 42.02290\n",
      "[RESULT]: Train. Epoch: 35, mae_loss: 7.00863668, time: 42.53947\n",
      "[RESULT]: Val. Epoch: 35, mse_loss: 2.53333971, time: 27.98066 time: 27.74012\n",
      "[RESULT]: Val. Epoch: 35, mae_loss: 11.03975222, time: 28.01533\n",
      "\n",
      "2021-08-18T03:29:01.805752\n",
      "LR: 4.9978203393768985e-05\n",
      "[RESULT]: Train. Epoch: 36, mse_loss: 3.09495388, time: 42.30240time: 41.80552\n",
      "[RESULT]: Train. Epoch: 36, mae_loss: 6.73380988, time: 42.31182\n",
      "[RESULT]: Val. Epoch: 36, mse_loss: 2.51229008, time: 23.86083 time: 23.65832\n",
      "[RESULT]: Val. Epoch: 36, mae_loss: 10.75351615, time: 23.86589\n",
      "\n",
      "2021-08-18T03:30:10.882803\n",
      "LR: 4.670809526264873e-05\n",
      "[RESULT]: Train. Epoch: 37, mse_loss: 3.11716279, time: 44.16846time: 43.66426\n",
      "[RESULT]: Train. Epoch: 37, mae_loss: 6.57578591, time: 44.17932\n",
      "[RESULT]: Val. Epoch: 37, mse_loss: 2.56564776, time: 27.76898 time: 27.56481\n",
      "[RESULT]: Val. Epoch: 37, mae_loss: 12.32324563, time: 27.80979\n",
      "\n",
      "2021-08-18T03:31:23.697566\n",
      "LR: 4.345208365863927e-05\n",
      "[RESULT]: Train. Epoch: 38, mse_loss: 3.06602955, time: 42.99834time: 42.50656\n",
      "[RESULT]: Train. Epoch: 38, mae_loss: 6.31780742, time: 43.04331\n",
      "[RESULT]: Val. Epoch: 38, mse_loss: 2.53264637, time: 25.43771 time: 25.27883\n",
      "[RESULT]: Val. Epoch: 38, mae_loss: 11.23336396, time: 25.44401\n",
      "\n",
      "2021-08-18T03:32:33.011104\n",
      "LR: 4.022411132330101e-05\n",
      "[RESULT]: Train. Epoch: 39, mse_loss: 3.02803679, time: 40.99554time: 40.49894\n",
      "[RESULT]: Train. Epoch: 39, mae_loss: 6.18507237, time: 41.00346\n",
      "[RESULT]: Val. Epoch: 39, mse_loss: 2.51516863, time: 26.87809 time: 26.64706\n",
      "[RESULT]: Val. Epoch: 39, mae_loss: 13.42073140, time: 26.88641\n",
      "\n",
      "2021-08-18T03:33:41.578070\n",
      "LR: 3.703800092974118e-05\n",
      "[RESULT]: Train. Epoch: 40, mse_loss: 3.04502101, time: 41.41600time: 40.93328\n",
      "[RESULT]: Train. Epoch: 40, mae_loss: 6.28287061, time: 41.42380\n",
      "[RESULT]: Val. Epoch: 40, mse_loss: 2.49962759, time: 25.56126 time: 25.32515\n",
      "[RESULT]: Val. Epoch: 40, mae_loss: 11.76212083, time: 25.58167\n",
      "\n",
      "2021-08-18T03:34:50.333997\n",
      "LR: 3.390739589180556e-05\n",
      "[RESULT]: Train. Epoch: 41, mse_loss: 3.01424753, time: 42.00556time: 41.51101\n",
      "[RESULT]: Train. Epoch: 41, mae_loss: 6.06837529, time: 42.01551\n",
      "[RESULT]: Val. Epoch: 41, mse_loss: 2.49384429, time: 24.46946 time: 24.25568\n",
      "[RESULT]: Val. Epoch: 41, mae_loss: 11.25338413, time: 24.47598\n",
      "\n",
      "2021-08-18T03:35:58.256407\n",
      "LR: 3.0845701940885835e-05\n",
      "[RESULT]: Train. Epoch: 42, mse_loss: 2.98057119, time: 42.46051time: 41.94563\n",
      "[RESULT]: Train. Epoch: 42, mae_loss: 6.05528508, time: 42.47019\n",
      "[RESULT]: Val. Epoch: 42, mse_loss: 2.50477065, time: 24.38846 time: 24.16458\n",
      "[RESULT]: Val. Epoch: 42, mae_loss: 11.23028409, time: 24.39594\n",
      "\n",
      "2021-08-18T03:37:05.836952\n",
      "LR: 2.7866029720519635e-05\n",
      "[RESULT]: Train. Epoch: 43, mse_loss: 2.98014907, time: 44.04543time: 43.45972\n",
      "[RESULT]: Train. Epoch: 43, mae_loss: 6.26146494, time: 44.08064\n",
      "[RESULT]: Val. Epoch: 43, mse_loss: 2.51577117, time: 24.65711 time: 24.42917\n",
      "[RESULT]: Val. Epoch: 43, mae_loss: 10.69437627, time: 24.71768\n",
      "\n",
      "2021-08-18T03:38:15.448431\n",
      "LR: 2.4981138644602184e-05\n",
      "[RESULT]: Train. Epoch: 44, mse_loss: 2.98814329, time: 43.97735time: 43.49561\n",
      "[RESULT]: Train. Epoch: 44, mae_loss: 6.01255726, time: 43.98588\n",
      "[RESULT]: Val. Epoch: 44, mse_loss: 2.47445399, time: 25.98140 time: 25.78194\n",
      "[RESULT]: Val. Epoch: 44, mae_loss: 11.34664980, time: 25.98851\n",
      "\n",
      "2021-08-18T03:39:26.925857\n",
      "LR: 2.2203382259617078e-05\n",
      "[RESULT]: Train. Epoch: 45, mse_loss: 2.98309953, time: 45.17378time: 44.63669\n",
      "[RESULT]: Train. Epoch: 45, mae_loss: 5.99083871, time: 45.22845\n",
      "[RESULT]: Val. Epoch: 45, mse_loss: 2.48018887, time: 25.36839 time: 25.16242\n",
      "[RESULT]: Val. Epoch: 45, mae_loss: 10.53918683, time: 25.37524\n",
      "\n",
      "2021-08-18T03:40:38.297816\n",
      "LR: 1.954465534485378e-05\n",
      "[RESULT]: Train. Epoch: 46, mse_loss: 2.94861507, time: 44.13227time: 43.63663\n",
      "[RESULT]: Train. Epoch: 46, mae_loss: 6.14945731, time: 44.17499\n",
      "[RESULT]: Val. Epoch: 46, mse_loss: 2.48407564, time: 35.38867 time: 35.15529\n",
      "[RESULT]: Val. Epoch: 46, mae_loss: 10.43458356, time: 35.39368\n",
      "\n",
      "2021-08-18T03:41:58.707595\n",
      "LR: 1.701634297713643e-05\n",
      "[RESULT]: Train. Epoch: 47, mse_loss: 2.93292470, time: 42.47038time: 41.96666\n",
      "[RESULT]: Train. Epoch: 47, mae_loss: 5.84561951, time: 42.48445\n",
      "[RESULT]: Val. Epoch: 47, mse_loss: 2.52477438, time: 24.33644 time: 24.13014\n",
      "[RESULT]: Val. Epoch: 47, mae_loss: 15.77799655, time: 24.34110\n",
      "\n",
      "2021-08-18T03:43:06.944238\n",
      "LR: 1.4629271778177219e-05\n",
      "[RESULT]: Train. Epoch: 48, mse_loss: 2.88473794, time: 42.56935time: 42.07950\n",
      "[RESULT]: Train. Epoch: 48, mae_loss: 5.75078918, time: 42.61072\n",
      "[RESULT]: Val. Epoch: 48, mse_loss: 2.49958559, time: 25.85080 time: 25.64938\n",
      "[RESULT]: Val. Epoch: 48, mae_loss: 10.70379271, time: 25.85726\n",
      "\n",
      "2021-08-18T03:44:16.317760\n",
      "LR: 1.239366355331991e-05\n",
      "[RESULT]: Train. Epoch: 49, mse_loss: 2.89803169, time: 44.51200time: 43.92738\n",
      "[RESULT]: Train. Epoch: 49, mae_loss: 5.70019749, time: 44.52386\n",
      "[RESULT]: Val. Epoch: 49, mse_loss: 2.48197201, time: 24.76109 time: 24.53308\n",
      "[RESULT]: Val. Epoch: 49, mae_loss: 10.84258996, time: 24.77172\n",
      "\n",
      "2021-08-18T03:45:26.800438\n",
      "LR: 1.0319091520200163e-05\n",
      "[RESULT]: Train. Epoch: 50, mse_loss: 2.90933893, time: 45.40726time: 44.91142\n",
      "[RESULT]: Train. Epoch: 50, mae_loss: 5.67895474, time: 45.41796\n",
      "[RESULT]: Val. Epoch: 50, mse_loss: 2.47347389, time: 26.26230 time: 26.05076\n",
      "[RESULT]: Val. Epoch: 50, mae_loss: 11.35991801, time: 26.26867\n",
      "\n",
      "2021-08-18T03:46:39.978459\n",
      "LR: 8.414439314757867e-06\n",
      "[RESULT]: Train. Epoch: 51, mse_loss: 2.92557246, time: 42.28364time: 41.68996\n",
      "[RESULT]: Train. Epoch: 51, mae_loss: 5.80678246, time: 42.29097\n",
      "[RESULT]: Val. Epoch: 51, mse_loss: 2.47138841, time: 25.46132 time: 25.21870\n",
      "[RESULT]: Val. Epoch: 51, mae_loss: 10.41067431, time: 25.46904\n",
      "\n",
      "2021-08-18T03:47:49.346267\n",
      "LR: 6.687862950144302e-06\n",
      "[RESULT]: Train. Epoch: 52, mse_loss: 2.88004174, time: 43.54886time: 43.02111\n",
      "[RESULT]: Train. Epoch: 52, mae_loss: 5.55992849, time: 43.55868\n",
      "[RESULT]: Val. Epoch: 52, mse_loss: 2.47159674, time: 25.32169 time: 25.12065\n",
      "[RESULT]: Val. Epoch: 52, mae_loss: 10.47392287, time: 25.32924\n",
      "\n",
      "2021-08-18T03:48:59.192689\n",
      "LR: 5.146755891421518e-06\n",
      "[RESULT]: Train. Epoch: 53, mse_loss: 2.89154867, time: 42.81945time: 42.33343\n",
      "[RESULT]: Train. Epoch: 53, mae_loss: 5.62609833, time: 42.84250\n",
      "[RESULT]: Val. Epoch: 53, mse_loss: 2.46809529, time: 24.39172 time: 24.15420\n",
      "[RESULT]: Val. Epoch: 53, mae_loss: 10.61653323, time: 24.39707\n",
      "\n",
      "2021-08-18T03:50:08.072971\n",
      "LR: 3.797717395610058e-06\n",
      "[RESULT]: Train. Epoch: 54, mse_loss: 2.91178973, time: 42.46115time: 41.96810\n",
      "[RESULT]: Train. Epoch: 54, mae_loss: 5.43996240, time: 42.47185\n",
      "[RESULT]: Val. Epoch: 54, mse_loss: 2.47354358, time: 23.29921 time: 23.09919\n",
      "[RESULT]: Val. Epoch: 54, mae_loss: 10.73310797, time: 23.32626\n",
      "\n",
      "2021-08-18T03:51:14.695368\n",
      "LR: 2.646524252657132e-06\n",
      "[RESULT]: Train. Epoch: 55, mse_loss: 2.90136706, time: 42.24353time: 41.76515\n",
      "[RESULT]: Train. Epoch: 55, mae_loss: 5.43401235, time: 42.44390\n",
      "[RESULT]: Val. Epoch: 55, mse_loss: 2.47152330, time: 25.35634 time: 25.15137\n",
      "[RESULT]: Val. Epoch: 55, mae_loss: 10.97284545, time: 26.57887\n",
      "\n",
      "2021-08-18T03:52:24.987004\n",
      "LR: 1.6981060483352512e-06\n",
      "[RESULT]: Train. Epoch: 56, mse_loss: 2.90732596, time: 44.80452time: 44.27466\n",
      "[RESULT]: Train. Epoch: 56, mae_loss: 5.60274407, time: 44.81457\n",
      "[RESULT]: Val. Epoch: 56, mse_loss: 2.47352823, time: 20.58430 time: 20.39528\n",
      "[RESULT]: Val. Epoch: 56, mae_loss: 10.13094872, time: 20.59454\n",
      "\n",
      "2021-08-18T03:53:31.073713\n",
      "LR: 9.565240549991333e-07\n",
      "[RESULT]: Train. Epoch: 57, mse_loss: 2.89550066, time: 40.52394time: 40.02860\n",
      "[RESULT]: Train. Epoch: 57, mae_loss: 5.45149502, time: 40.53477\n",
      "[RESULT]: Val. Epoch: 57, mse_loss: 2.47201813, time: 21.63707 time: 21.41278\n",
      "[RESULT]: Val. Epoch: 57, mae_loss: 10.15328025, time: 21.64660\n",
      "\n",
      "2021-08-18T03:54:33.967920\n",
      "LR: 4.2495384059399187e-07\n",
      "[RESULT]: Train. Epoch: 58, mse_loss: 2.87275891, time: 43.53174time: 43.02696\n",
      "[RESULT]: Train. Epoch: 58, mae_loss: 5.48416706, time: 43.54308\n",
      "[RESULT]: Val. Epoch: 58, mse_loss: 2.46688778, time: 21.49601 time: 21.26547\n",
      "[RESULT]: Val. Epoch: 58, mae_loss: 10.56853672, time: 21.50920\n",
      "\n",
      "2021-08-18T03:55:41.146488\n",
      "LR: 1.0567167038603568e-07\n",
      "[RESULT]: Train. Epoch: 59, mse_loss: 2.93259896, time: 43.21220time: 42.69407\n",
      "[RESULT]: Train. Epoch: 59, mae_loss: 5.54736950, time: 43.23392\n",
      "[RESULT]: Val. Epoch: 59, mse_loss: 2.47368505, time: 24.02874 time: 23.80401\n",
      "[RESULT]: Val. Epoch: 59, mae_loss: 10.31247879, time: 24.03645\n"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(valid_dataset),\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = SANet().cuda()\n",
    "test_net = nn.DataParallel(test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SANet(\n",
       "    (FME): Xception(\n",
       "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (block1): Block(\n",
       "        (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): SeparableConv2d(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): SeparableConv2d(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): SeparableConv2d(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): SeparableConv2d(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): SeparableConv2d(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (block3): Block(\n",
       "        (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): SeparableConv2d(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (block6): Block(\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (block7): Block(\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (block11): Block(\n",
       "        (skip): Conv2d(728, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (block12): Block(\n",
       "        (skip): Conv2d(728, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skipbn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (rep): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): SeparableConv2d(\n",
       "            (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "            (pointwise): Conv2d(728, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv3): SeparableConv2d(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): SeparableConv2d(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (DME): Sequential(\n",
       "      (0): Conv2d(512, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'/mnt/home/zpengac/USERDIR/count/drone_benchmark/DENet-drone_vehicle-8.22-384/best-checkpoint-119epoch.bin')\n",
    "test_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, dmaps, fns, points = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = test_net(imgs.cuda())/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = preds.sum(dim=[-1,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384, 688])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dmaps.sum(dim=[-1,-2])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29.0312]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.1983]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as pnsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 988/988 [01:44<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 38s, sys: 51min 32s, total: 1h 5min 10s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pre_count = []\n",
    "gt_count = []\n",
    "gt_points = []\n",
    "avg_ssim = AverageMeter()\n",
    "avg_pnsr = AverageMeter()\n",
    "for imgs, dmaps, fns, points in tqdm(val_loader):\n",
    "    with torch.no_grad():\n",
    "        imgs = imgs.cuda().float()\n",
    "        preds = test_net(imgs) / LOG_PARA\n",
    "    dmaps = dmaps / LOG_PARA\n",
    "    \n",
    "    for pred, dmap in zip(preds, dmaps):\n",
    "        pred_array = pred.detach().cpu().numpy().squeeze()\n",
    "        dmap_array = dmap.detach().cpu().numpy().squeeze()\n",
    "        avg_ssim.update(ssim(dmap_array, pred_array, data_range=dmap_array.max()-dmap_array.min()))\n",
    "        avg_pnsr.update(pnsr(dmap_array, pred_array, data_range=dmap_array.max()-dmap_array.min()))\n",
    "    \n",
    "    pre_count.extend(preds.sum(dim=[-1,-2]).detach().cpu().numpy())\n",
    "    \n",
    "    gt_count.extend(dmaps.sum(dim=[-1,-2]).detach().cpu().numpy())\n",
    "    \n",
    "    #gt_p = []\n",
    "    #for p in points:\n",
    "    #    gt_p.append(len(p))\n",
    "    #gt_points.extend(gt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(pre_count,gt_count)\n",
    "mse = mean_squared_error(pre_count,gt_count)\n",
    "nae = mae * len(pre_count) / np.sum(gt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Paras: 11.738809\n",
      "MAE: 5.984570503234863, MSE: 106.10637664794922, NAE: 0.16676381446060337\n",
      "SSIM: 0.9854356642483117, PNSR: 35.964205439242555\n"
     ]
    }
   ],
   "source": [
    "def count_parameters_in_MB(model):\n",
    "    return np.sum(np.prod(v.size()) for name, v in model.named_parameters() if \"auxiliary\" not in name) / 1e6\n",
    "\n",
    "print(f'#Paras: {count_parameters_in_MB(test_net)}')\n",
    "print(f'MAE: {mae}, MSE: {mse}, NAE: {nae}')\n",
    "print(f'SSIM: {avg_ssim.avg}, PNSR: {avg_pnsr.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
